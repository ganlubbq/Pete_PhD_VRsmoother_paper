\documentclass[journal]{IEEEtran}


\usepackage{cite}
\usepackage[pdftex]{graphicx}
\usepackage[cmex10]{amsmath}
\usepackage{amsfonts}
\usepackage{algorithmic}
\usepackage{array}
\usepackage{mdwmath}
\usepackage{mdwtab}
%\usepackage{eqparbox}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{fixltx2e}
\usepackage{url}
\usepackage{color}

\graphicspath{{./images/}{./images/finance/}{./images/tracking/}}
%\interdisplaylinepenalty=1000

\newenvironment{meta}[0]{\color{red} \em}{}

% correct bad hyphenation here
\hyphenation{}

\begin{document}

\title{Smoothing Algorithms for Variable Rate Models}

\author{Pete~Bunch,~\IEEEmembership{Member,~IEEE,}
        Simon~Godsill,~\IEEEmembership{Member,~IEEE,}% <-this % stops a space
\thanks{P. Bunch and S. Godsill are with the Department
of Engineering, Cambridge University, UK. email: \{pb404,sjg30\}@cam.ac.uk}% <-this % stops a space
\thanks{Manuscript received January 01, 1901; revised January 02, 1901.}}

% The paper headers
\markboth{IEEE Transaction in Signal Processing,~Vol.~1, No.~1, January~1901}%
{Bunch \& Godsill: Smoothing Algorithms for Variable Rate Models}

% make the title area
\maketitle

\begin{abstract}
Standard state-space methods assume that the latent state evolves uniformly over time, and can be modelled with a discrete-time process synchronous with the observations. This may be a poor representation of some systems in which the state evolution displays discontinuities in its behaviour. For such cases, a variable rate model may be more appropriate; the system dynamics are conditioned on a set of random changepoints which constitute a marked point process. In this paper, new particle smoothing algorithms are presented for use with conditionally linear-Gaussian and conditionally deterministic dynamics. These are demonstrated on problems of financial modelling and target tracking. Results indicate that the smoothing approximations provide more accurate and more diverse representations of the state posterior distributions.
\end{abstract}

\begin{IEEEkeywords}
Bayesian inference, state-space model, variable rate, particle filter, filtering, smoothing
\end{IEEEkeywords}



\section{Introduction}

\IEEEPARstart{T}{he} objective of sequential Bayesian inference is to estimate an imperfectly observed quantity as it varies over time. This is accomplished through the use of probabilistic models for the state evolution and measurement processes. Often, the latent state is a continuously varying quantity, whereas the observations are made at a discrete set of times. In these circumstances, it is simplest to discretise the state onto the same set of times as the observations. When the system is also Markovian, this leads to the standard ``fixed rate'' hidden Markov model (HMM). The standard HMM is poorly suited to systems where the state evolution contains discontinuities; for example, the price of a financial asset which may display large jumps at random times between periods of diffusion-like behaviour, or the kinematic state of a manoeuvring vehicle which may have sudden changes in the acceleration when turns begin or end. Such problems can be handled more naturally using a ``variable rate'' model, in which the state dynamics are conditioned upon a set of changepoints which characterise transitions in behaviour.

In a variable rate model, the set of changepoints and associated parameters are modelled as a marked point process (MPP), the mathematical properties of which are set out thoroughly in \cite{Jacobsen2006}. Conditional upon this MPP the state evolves according to some benign dynamics. In \cite{Godsill2007,Whiteley2011}, the conditional state evolution is treated as deterministic, while in \cite{Godsill2007a,Christensen2012} a conditionally linear-Gaussian state model is considered.

The posterior distribution for the changepoint MPP is inherently nonlinear, and cannot be calculated analytically. Instead, inference may be conducted using numerical approximations. The particle filter (introduced by \cite{Gordon1993}) and smoother (see \cite{Doucet2000a,Godsill2004}) are schemes which approximate a posterior distribution using a set of samples, or ``particles'', drawn sequentially from it.  A thorough introduction to particle filtering and smoothing methods can be found in \cite{Cappe2007,Doucet2009}. In \cite{Godsill2007a,Godsill2007,Whiteley2011}, the particle filter was adapted for use with variable rate models, resulting in the variable rate particle filter (VRPF).

The VRPF allows the changepoint sequence -- and hence the current state -- to be estimated sequentially as observations are received. However, estimates can often be improved later once further observations have been made. In this paper, we address the problem of smoothing in variable models, i.e. the estimation of the changepoint sequence and latent state given all the observations. This is achieved with an efficient backward sweep through the observations, in a similar manner to the method for standard HMMs described in \cite{Godsill2004}. Two new schemes are introduced: one for conditionally linear-Gaussian models which exploits the method of Rao-Blackwellisation; and a second for use with conditionally-deterministic models which uses an augmented target distribution in the style of an SMC sampler \cite{DelMoral2006}.

We introduce the general structure of variable rate models in section~\ref{sec:vr_models}. The VRPF is reviewed in section~\ref{sec:vrpf}, and new variable rate smoothing algorithms are described in section~\ref{sec:vrps}. In section~\ref{sec:simulations}, particular examples of variable rate models are presented and algorithm performance is demonstrated in a series of simulations.



\section{Variable Rate Models} \label{sec:vr_models}

We consider a general model from time $0$ to $T$, between which observations, $\{y_1 \dots y_N\}$, are made at times $\{t_1 \dots t_N = T\}$. During this period, an unknown number of changepoints, $K$, occur at times $\{\tau_0 = 0, \tau_1 \dots \tau_K \}$, each with associated changepoint parameters, $\{ u_0, u_1 \dots u_K \}$. The pairs $\{\tau_k, u_k\}$ are the elements of an marked point process (MPP). The latent state is a continuous-time process denoted $x(t)$. Discrete sets containing multiple values over time will be written as, e.g. $y_{1:n} = \{y_1 \dots y_n\}$.

The objective for inference will be to estimate the changepoint sequence. This will be denoted as $\theta = \{\tau_{0:K}, u_{0:K}\}$. At a particular time $t_n$, the sequence will be divided into past $\theta_n = \{\tau_{j}, u_{j} \forall j : 0 \leq \tau_j < t_n \}$, and future $\theta_n^+ = \{\tau_{j}, u_{j} \forall j : t_n \leq \tau_j < T \}$. It will also be useful to define a variable for the changepoints which occur in the interval $[t_{n-1},t_n)$, $\theta_{n \setminus n-1} = \{\tau_{j}, u_{j} \forall j : t_{n-1} \leq \tau_j < t_n \}$.

For notational simplicity, the following counting variables are introduced to keep track of the most recent changepoint to have occurred,
%
\begin{IEEEeqnarray}{rCl}
 K(t)  & = & \max(k : \tau_k<t) \\
 K_n   & = & K(t_n)     .
\end{IEEEeqnarray}

The changepoint sequence is assumed to be a Markov process.
%
\begin{IEEEeqnarray}{rCl}
 \{\tau_k, u_k\} & \sim & p(\tau_k, u_k|\tau_{k-1}, u_{k-1}) \label{eq:cp_model}
\end{IEEEeqnarray}

This density will be constructed such that $P(\tau_k < \tau_{k-1}) = 0$.

In the manner of \cite{Whiteley2011}, a survivor function is defined as the probability that no new changepoint occurs before a given time,
%
\begin{IEEEeqnarray}{rCl}
 S(\tau_k, u_k, t) &=& P(\tau_{k+1}>t|\tau_k, u_k) \nonumber \\
              &=& 1 - \int_{\tau_k}^{t} p(\xi|\tau_{k}, u_k) d\xi     .
\end{IEEEeqnarray}

It is now possible to write down a prior for the changepoint sequence, where we use the convention that $\tau_0 = 0$. The existence of such a density for a MPP is addressed in \cite{Jacobsen2006}.

\begin{IEEEeqnarray}{rCl}
p(\theta_n) & = & S(\tau_{K_n},t_n) p(u_0) \prod_{k=1}^{K_n} p(\tau_k, u_k| \tau_{k-1}, u_{k-1}) \label{eq:cp_sequence_prior}
\end{IEEEeqnarray}



\subsection{Conditionally Linear-Gaussian Models}

The first class of variable rate models to be considered is those whose state dynamics are linear-Gaussian conditional on the changepoint sequence. Such a model may be discretised onto the set of observation times in exactly the same manner as a standard the standard HMM.
%
\begin{IEEEeqnarray}{rCl}
 x_n & = & A_n(\theta_{n})x_{n-1} + w_n \\
 y_n & = & C_n(\theta_{n})x_n + v_n       ,
\end{IEEEeqnarray}

where,
%
\begin{IEEEeqnarray}{rCl}
 w_n & \sim & \mathcal{N}(w_n|0, Q_n(\theta_{n})) \\
 v_n & \sim & \mathcal{N}(v_n|0, R_n(\theta_{n}))       .
\end{IEEEeqnarray}

In addition, the prior state distribution should be Gaussian, with known mean and variance.
%
\begin{IEEEeqnarray}{rCl}
 x_0 & \sim & \mathcal{N}(x_0|m_0, P_0)       .
\end{IEEEeqnarray}

If the changepoint sequence is known, or has been estimated, then the state values, $x_n$ may be inferred using optimal Kalman filtering and smoothing recursions. As well as the basic Kalman filter \cite{Kalman1960}, the Rauch-Tung-Striebel (RTS) smoother \cite{Rauch1965} and two-filter smoother \cite{Fraser1969} will prove useful for this step.

Conditionally linear-Gaussian variable rate models were introduced in \cite{Godsill2007a} for a financial inference algorithm. Changepoints correspond to jumps in the value or trend of a security, at which points the process covariance, $Q_n(\theta_n)$, is inflated.



\subsection{Conditionally Deterministic Models}

The second class of variable rate models for consideration is those in which the state is completely specified by the changepoint sequence, with no additional random components. Such a process is commonly referred to as ``piecewise-deterministic'', as the latent state follows a deterministic path between changepoints. In this case, it is not necessary to discretise the state -- it may be kept as a continuous variable.

In general, the state dynamics will be governed by a differential equation which may depend on the entire changepoint sequence. Here we assume that only the most recent changepoint is significant.
%
\begin{IEEEeqnarray}{rCl}
 dx(t) & = & \mathrm{f}(x(t), \tau_{K(t)}, u_{K(t)})     .
\end{IEEEeqnarray}

By introducing a new sequence, $\{ x_0, x_1 \dots x_K \}$, which denotes the value of the state at each changepoint (i.e. $x(\tau_k)$), and assuming that an analytic solution exists, a state transition function may be found,
%
\begin{IEEEeqnarray}{rCll}
 x(t) & = & f(x_{K_n}, u_{K_n}, \tau_{K_n}, t) &, \tau_{K_n} < t \leq \tau_{K_{n}+1}    \label{eq:disc_time_state_diff_eq}     .
\end{IEEEeqnarray}

By choosing $t = \tau_{K_{n}+1}$, this equation specifies the state at the next changepoint time. Similarly, by choosing $t=t_n$, the state at the observation times may be calculated --- these points will be denoted $\hat{x}_n$. To complete the model, a probabilistic measurement model must be devised for the observation process, $p(y_n|\hat{x}_n)$.

For convenience, we assume that $x_0$ is known in the following sections. This means that $x(t)$ may be calculated deterministically for all $t$ given $\theta$. This condition is easily relaxed by including $x_0$ as a random variable in the posterior distribution.

Target tracking algorithms are commonly based upon fixed rate models (see, e.g. \cite{Li2003} for a thorough survey), in which the target kinematics (position, velocity, etc.) are estimated at a set of fixed times at which observations (e.g. radar measurements) are made. In \cite{Godsill2007a,Godsill2007,Whiteley2011}, variable rate models were introduced for tracking, in which the state trajectory is divided up by a set of changepoints between which the motion follows a deterministic path governed by motion parameters (accelerations, etc.) which are fixed for that division.



\section{The Variable Rate Particle Filter} \label{sec:vrpf}

The variable rate particle filter (VRPF) is described in \cite{Godsill2007,Godsill2007a,Whiteley2011}. The objective of the algorithm is to sequentially estimate the posterior distribution of the changepoint sequence, $p(\theta_{n}| y_{1:n})$, at each time $t_n$. This distribution may be expanded using Bayes' rule,
%
\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{ p(\theta_{n}|y_{1:n}) \propto p(y_n|\theta_{n}, y_{1:n-1}) } \nonumber \\
 \qquad & & \times p(\theta_{n \setminus n-1}|\theta_{n-1}) p(\theta_{n-1}|y_{1:n-1}) \label{eq:vrpf_target}     .
\end{IEEEeqnarray}

The transition term, $p(\theta_{n \setminus n-1} | \theta_{n-1})$, has a similar form to the changepoint prior of (\ref{eq:cp_sequence_prior}) \cite{Jacobsen2006}. An additional survivor function is included to account for the condition that changepoints cannot occur before $t_{n-1}$.  %, comprising a product of density terms (one for each new changepoint) and a survivor function term.% In the particular (but common) case that no new changepoints occur within the interval, the density consists of a probability mass on the empty set, with weight $P(\tau_{K_n+1} > t_n | \tau_{K_n+1} > t_{n-1}, \tau_{K_n} )$.
%
\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{p(\theta_{n \setminus n-1} | \theta_{n-1}) = S(\tau_{K_n}, t_n) / S(\tau_{K_{n-1}+1}, t_{n-1}) } \nonumber \\
 \qquad  \qquad & & \times \prod\limits_{j:t_{n-1} \leq \tau_j < t_n} p(\tau_j, u_j| \tau_{j-1}, u_{j-1})  \label{eq:cp_sequence_trandens}
\end{IEEEeqnarray}
%\begin{IEEEeqnarray}{rCl}
%\IEEEeqnarraymulticol{3}{l}{p(\theta_{n \setminus n-1} | \theta_{n-1})} \nonumber \\
%    & = & p(\tau_{K_{n-1}+1:K_n}, u_{K_{n-1}+1:K_n}, \tau_{K_n+1}>t_n|\tau_{K_{n-1}+1}>t_{n-1}, \tau_{K_{n-1}}, u_{K_{n-1}}) \nonumber \\
%    & = & \begin{cases} S(\tau_{K_n}, t_n) \prod\limits_{j:t_{n-1} \leq \tau_j < t_n} p(\tau_j, u_j| \tau_{j-1}, u_{j-1}, \tau_j>t_{n-1}) & K_n > K_{n-1} \\
%                        S(\tau_{K_n}, t_n) / S(\tau_{K_n}, t_{n-1}) & K_n = K_{n-1} \end{cases} \IEEEeqnarraynumspace \label{eq:cp_sequence_trandens}
%\end{IEEEeqnarray}

%For all but the first changepoint in the interval, the density is given by the prior model of (\ref{eq:cp_model}). For the first changepoint, indexed by $k=K_{n-1}+1$, we must account for the fact that it cannot occur before $t_{n-1}$,
%%
%\begin{IEEEeqnarray}{rCl}
%\IEEEeqnarraymulticol{3}{l}{p(\tau_{k}, u_{k}| \tau_{k-1}, u_{k-1}, \tau_{k}>t_{n-1})} \nonumber \\
%  & = & \frac{1}{S(\tau_{k-1}, t_{n-1})} \begin{cases} p(\tau_{k}, u_{k}| \tau_{k-1}, u_{k-1}) & \tau_{k} > t_{n-1} \\ 0 & \tau_{k} < t_{n-1} \end{cases}  \IEEEeqnarraynumspace \label{eq:cp_cond_model}   .
%\end{IEEEeqnarray}

Practically, because changepoints will be relatively rare events, it is not likely that more than one new changepoint will occur between $t_{n-1}$ and $t_n$.

The target distribution of (\ref{eq:vrpf_target}) cannot be calculated analytically, but may be approximated numerically. A particle filter is an algorithm for approximating a probability distribution using a set of weighted samples (or ``particles'') drawn from that distribution. In this case, each particle will be a set of changepoint times and parameters.
%
\begin{equation}
 \hat{p}(\theta_{n}|y_{1:n}) = \sum_j w_n^{(j)} \delta_{\theta_{n}^{(j)}}(\theta_{n})
\end{equation}

where $\delta_x(X)$ is a dirac probability mass at $X=x$.

The particle filter works recursively. At the $n$th step, a particle, $\theta_{n-1}^{(i)}$, is first resampled from those approximating the filtering distribution at the $(n-1)$th step, using an appropriately chosen set of proposal weights.
%
\begin{equation}
 q(\theta_{n-1}) = \sum_j v_{n-1}^{(j)} \delta_{\theta_{n-1}^{(j)}}(\theta_{n-1})
\end{equation}

The choice of weights determines the type of resampling used. The simplest choice, $v_{n-1}^{(j)} = 1/N_F$ (where $N_F$ is the number of filter particles) may be achieved by simply omitting this step all together and using the particles of $\hat{p}(\theta_{n-1}|y_{1:n-1})$. This, however, leads to degeneracy of the particle weights over time. Conventional resampling is achieved by using $v_{n-1}^{(j)} = w_{n-1}^{(j)}$. Any other choice results in an auxiliary particle filter \cite{Pitt1999}. For further discussion of resampling, see \cite{Cappe2007,Doucet2009,Douc2005}.

Next, an extension to the changepoint sequence, $\theta_{n \setminus n-1}^{(i)}$, is proposed from an importance distribution, $q(\theta_{n \setminus n-1}|\theta_{n-1}^{(i)}, y_n)$, and concatenated with $\theta_{n-1}$ to create an estimate of $\theta_n$. Finally, the particle is weighted according to the ratio of the target and proposal densities.
%
\begin{IEEEeqnarray}{rCl}
w_n^{(i)} & = & \frac{ p(\theta_{n}^{(i)}|y_{1:n}) }{ q(\theta_{n}) } \nonumber \\
    & \propto & \frac{ p(y_n|\theta_n, y_{1:n-1}) p(\theta_{n \setminus n-1}|\theta_{n-1}) p(\theta_{n-1}|y_{1:n-1}) }{ q(\theta_{n-1}) q(\theta_{n \setminus n-1}|\theta_{n-1}^{(i)}, y_n) } \nonumber \\
    & =       & \frac{w_{n-1}^{(i)}}{v_{n-1}^{(i)}} \times \frac{ p(y_n|\theta_n, y_{1:n-1}) p(\theta_{n \setminus n-1}|\theta_{n-1}) }{ q(\theta_{n \setminus n-1}|\theta_{n-1}^{(i)}, y_n) } \label{eq:vrpf_weights}
\end{IEEEeqnarray}

The normalisation may be enforced by scaling the weights so that they sum to $1$.

For the most basic ``bootstrap'' \cite{Gordon1993} form of the VRPF, $\theta_{n \setminus n-1}$ may be proposed from the prior transition density (\ref{eq:cp_sequence_trandens}). This can be achieved by sampling new changepoints sequentially from the transition model (\ref{eq:cp_model}) until one falls after the current time, $t_n$. This final future changepoint is discarded. (This process can be thought of as sampling the entire future changepoint sequence from $t_{n-1}$ onwards, and then marginalising those which fall after $t_n$.) The bootstrap proposal leads to the usual simplification of the weight formula. % (apart from the first which is sampled from (\ref{eq:cp_cond_model}))
%
\begin{IEEEeqnarray}{rCl}
w_n^{(i)} & = & \frac{w_{n-1}^{(i)}}{v_{n-1}^{(i)}} \times p(y_n|\hat{x}_n) \label{eq:bootstrap_vrpf_weights}
\end{IEEEeqnarray}

%The choice of proposal weights, $\{v_{n-1}^{(i)}\}$, requires particular attention in the design of VRPFs. In some models a changepoint may not have an immediate effect on the observations, especially if a jump occurs in some quantity which is only observed via its integral, e.g. if there is a jump in the acceleration of a moving object, yet only the position is measured, the change will not be apparent until several more observations have been made. In the meantime, particles which contain a changepoint at the correct time may all have been removed by the resampling process. To avoid this loss of good particles, proposal weights should be chosen which preserve a significant number of low-weight particles. One scheme which has been found to work well is described in \cite{Godsill2007}, in which proposal weights are given by:

In \cite{Godsill2007}, the following choice of proposal weights was found to work well, as it preserves low probability particles which might turn out to be good estimates at later time steps,
%
\begin{IEEEeqnarray}{rCl}
v_{n-1}^{(i)} & \propto & \max ( 1, N_F w_{n-1}^{(i)} )     .
\end{IEEEeqnarray}

It only remains to consider the likelihood term required for evaluation of the importance weights, $p(y_n|\theta_n, y_{1:n-1})$. The form of this term depends on the particular model under consideration. In the following sections, the likelihood expressions for the conditionally linear-Gaussian and deterministic cases are considered.



\subsection{Conditionally Linear-Gaussian Likelihoods} \label{sec:rb-vrpf}

For a conditionally linear-Gaussian model, the required likelihood term, $p(y_n|\theta_n, y_{1:n-1})$ is the predictive distribution estimated by the Kalman filter. Conveniently, the Kalman filter also provides us with an estimate of the current state given the changepoint sequence and all the preceding observations. It follows from the the Gaussian dynamics and prior that these distributions are all Gaussian as well, \cite{Grewal2002},
%
\begin{IEEEeqnarray}{rCl}
 p(x_n|\theta_{n}, y_{1:n-1}) & = & \mathcal{N}(x_n|m_n^-, P_n^-) \\
 p(x_n|\theta_{n}, y_{1:n}) & = & \mathcal{N}(x_n|m_n, P_n) \\
 p(y_n|\theta_{n}, y_{1:n-1}) & = & \mathcal{N}(y_n|\mu_n, S_n)     ,
\end{IEEEeqnarray}

with means and variances given by the following standard recursions (dependence on $\theta_{n}$ suppressed for clarity),
%
\begin{IEEEeqnarray}{rCl}
 m_n^- & = & A_n m_{n-1} \label{eq:kf_predict_start} \\
 P_n^- & = & A_n P_{n-1} A_n^T + Q_n \\
 \mu_n & = & C_n m_n^- \\
 S_n   & = & C_n P_n^- C_n^T + R_n \label{eq:kf_predict_stop} \\
 K_n   & = & P_n^- C_n^T S_n^{-1} \label{eq:kf_update_start}\\
 m_n   & = & m_n^- + K_n (y_n - \mu_n) \\
 P_n   & = & P_n^- - K_n S_n K_n^T \label{eq:kf_update_stop}    .
\end{IEEEeqnarray}

This completes the requirements for the particle filter, resulting in the final algorithm shown in Fig.~\ref{alg:RBVRPF}.% The concept of estimating the posterior for just the changepoint sequence with a particle filter rather than the joint posterior over changepoints and linear states is an example of Rao-Blackwellisation (see, e.g. \cite{Casella1996,Doucet2000}), so this algorithm is known as the Rao-Blackwellised variable rate particle filter (RB-VRPF) \cite{Godsill2007a,Christensen2012}.

\begin{figure}
\fbox{\parbox{\columnwidth}{
\begin{algorithmic}[1]
\linespread{1.5} \selectfont
\STATE For each $i$, initialise particle changepoint sequence with $\{\theta_{0}^{(i)}\} \gets \{\tau_0^{(i)}, u_0^{(i)}\}$, where $\tau_0^{(i)}=0$ and $u_0^{(i)} \sim p(u_0)$.
\STATE For each $i$, initialise particle sufficient statistics, $m_0^{(i)}$ and $P_0^{(i)}$ with prior values.
\FOR{$n=1 \dots N$}
  \FOR{$i=1 \dots N_F$}
  	\STATE Sample a history $\theta_{n-1}^{(i)} \sim \sum_j v_{n-1}^{(j)} \delta_{\theta_{n-1}^{(j)}}(\theta_{n-1})$.
    \STATE Propose an extension $\theta_{n \setminus n-1}^{(i)} \sim q(\theta_{n \setminus n-1} | \theta_{n-1}^{(i)})$.
    \STATE Add extension to sequence $\theta_n^{(i)} \gets \theta_{n-1}^{(i)} \cup \theta_{n \setminus n-1}^{(i)}$.
    \STATE Predict observation mean and covariance $\mu_n^{(i)}$ and $S_n^{(i)}$ using (\ref{eq:kf_predict_start})~to~(\ref{eq:kf_predict_stop}).
    \STATE Calculate weight $w_n^{(i)}$ using (\ref{eq:vrpf_weights}).
    \STATE Update state mean and covariance $m_n^{(i)}$ and $P_n^{(i)}$ using (\ref{eq:kf_update_start})~to~(\ref{eq:kf_update_stop}).
  \ENDFOR
  \STATE Scale weights such that $\sum_i w_n^{(i)}=1$.
\ENDFOR
\end{algorithmic}
}}
\caption{Rao-Blackwellised variable rate particle filter}
\label{alg:RBVRPF}
\end{figure}



\subsection{Conditionally Deterministic Likelihoods} \label{sec:pd-vrpf}

When a conditionally deterministic model is used, the state at observation time $t_n$ is specified by the changepoint sequence $\theta_n$ (plus the initial state, $x_0$), using (\ref{eq:disc_time_state_diff_eq}). Thus, the required likelihood term is simply given by,
%
\begin{IEEEeqnarray}{rCl}
 p(y_n|\theta_{n}, y_{1:n-1}) & = & p(y_n|\hat{x}_n)     .
\end{IEEEeqnarray}

This leads to a particle filter for variable rate models with conditionally deterministic dynamics, summarised in Fig.~\ref{alg:VRPF}.% The resulting trajectories $x(t)^{(i)}$ for each particle are realisations from a piecewise-deterministic process, so this algorithm is named the piecewise-deterministic variable rate particle filter (PD-VRPF).

\begin{figure}
\fbox{\parbox{\columnwidth}{
\begin{algorithmic}[1]
\linespread{1.5} \selectfont
\STATE For each $i$, initialise particle changepoint sequence with $\{\theta_{0}^{(i)}\} \gets \{\tau_0^{(i)}, u_0^{(i)}\}$, where $\tau_0^{(i)}=0$ and $u_0^{(i)} \sim p(u_0)$.
\FOR{$n=1 \dots N$}
  \FOR{$i=1 \dots N_F$}
  	\STATE Sample a history $\theta_{n-1}^{(i)} \sim \sum_j v_{n-1}^{(j)} \delta_{\theta_{n-1}^{(j)}}(\theta_{n-1})$.
    \STATE Propose an extension $\theta_{n \setminus n-1}^{(i)} \sim q(\theta_{n \setminus n-1}|\theta_{n-1}^{(i)}, y_{n})$.
    \STATE Add extension to sequence $\theta_n^{(i)} \gets \theta_{n-1}^{(i)} \cup \theta_{n \setminus n-1}^{(i)}$.
    \STATE Calculate state $\hat{x}_n$ using (\ref{eq:disc_time_state_diff_eq}).
    \STATE Calculate weight $w_n^{(i)}$ using (\ref{eq:vrpf_weights}).
  \ENDFOR
  \STATE Scale weights such that $\sum_i w_n^{(i)}=1$.
\ENDFOR
\end{algorithmic}
}}
\caption{Piecewise deterministic variable rate particle filter}
\label{alg:VRPF}
\end{figure}



\subsection{Improving the Variable Rate Particle Filter}

The bootstrap versions of the VRPF may perform poorly if changepoints are not obvious until significantly after they occur. For example, in a tracking example, if a jump occurs in the acceleration, but only the position is observed, then this change may not be obvious until a number of observations have arrived. In this case, the estimation may be improved by the introduction of resample-move (RM) steps \cite{Gilks2001}. In an RM scheme, optional Metropolis-Hastings (MH) moves are conducted to alter the particle states after the importance sampling has taken place. For variable rate models, any one of the previous changepoints, $\tau_k$, or associated parameters, $u_k$, could be adjusted. Because more observations are available than when the changepoint was first proposed, it may be possible to construct more informed proposals and so move the changepoints towards regions with higher posterior probability. It is even possible to retrospectively add or remove changepoints, using reversible jump MH moves \cite{Green1995}. Variable rate particle filters using RM with piecewise deterministic models are described in \cite{Whiteley2011,Gilholm2008}.

Rather than conducting the IS and MH steps separately, it is possible to combine them using the framework of SMC samplers \cite{DelMoral2006}. This was suggested in \cite{Whiteley2011}, again for piecewise deterministic dynamics, but the extension to conditionally linear-Gaussian models is straightforward.

%Filtering schemes which alter past changepoints -- whether using an SMC sampler or RM -- are computationally expensive, because many likelihood calculations must be conducted, for each observation from the time of the change onwards. In some cases, it may be simpler to just use a bootstrap filter with more particles.



\section{Variable Rate Particle Smoothing} \label{sec:vrps}

A filter conducts inference sequentially as new observations are introduced. The purpose of a smoother is to produce a revised estimate once all the observations have been made, using future values to improve upon the filter performance. Estimating changepoints online is a challenging task because the presence of a change may not be obvious until after it has happened. Thus, a smoothing algorithm is expected to achieve significantly improved performance at changepoint estimation.

The target distribution for a variable rate smoothing algorithm is the posterior distribution over the entire changepoint sequence, $p(\theta|y_{1:N})$. This is the distribution approximated by the final step of the VRPF. However, in the same manner as the fixed rate filter-smoother of \cite{Kitagawa1996}, this approximation is likely to lack path-space diversity --- because of the necessary resampling step in the filtering algorithm, the particles all share the same set of changepoints before a particular time, with variation only appearing for changepoints closer to $T$. For a better characterisation of the smoothing distribution, it is necessary to rejuvenate the set of particles. This is achieved with a backward pass through the observations in a similar manner to the forward-backward method described in \cite{Godsill2004}.



\subsection{Conditionally Linear-Gaussian Smoothing} \label{sec:rb-vrps}

At time $t_n$, the target distribution may be factorised as follows,
%
\begin{IEEEeqnarray}{rCl}
 p(\theta|y_{1:N}) = p(\theta_{n}^{+}|y_{1:N}) p(\theta_{n}|\theta_{n}^{+}, y_{1:N})     .
\end{IEEEeqnarray}

This suggests a sequential strategy for particle smoothing. Starting with a low diversity set of particles from $p(\theta|y_{1:N})$, we first marginalise $\theta_{n}$ by simply discarding the changepoints before $t_n$. New values of $\theta_{n}$ are then sampled from the conditional distribution, $p(\theta_{n}|\theta_{n}^{+}, y_{1:N})$, which is approximated using the filter particles, and the past and future sequences are concatenated. By iterating backwards from $n = N \dots 1$, a diverse set of particles approximating $p(\theta|y_{1:N})$ will be generated.

%A particle drawn from $p(\theta_{n}^{+}|y_{1:N})$ may be extended backwards by sampling from the conditional distribution, $p(\theta_{n}|\theta_{n}^{+}, y_{1:N})$ and concatenating the past and future sequences. The new particle will be a sample from the target distribution, but the resulting approximation will still suffer from low path-space diversity before time $t_{n-1}$. Therefore, $\theta_{n-1}$ is marginalised by simply discarding the changepoints which occur before this time. This results in a particle drawn from $p(\theta_{n-1}^{+}|y_{1:N})$. The procedure then continues recursively. After a complete backwards pass through the observations, a single particle from the target distribution will have been generated. The process is then repeated until sufficient samples are obtained.

%At step $n$ for a given particle, the future changepoint sequence may be considered to be fixed. It remains to devise a method for drawing samples from the backwards conditional distribution, $p(\theta_{n}|\theta_{n}^{+}, y_{1:N})$.

It remains to devise a scheme for sampling the conditional distribution, $p(\theta_{n}|\theta_{n}^{+}, y_{1:N})$. The simplifications used by the fixed rate particle smoother which exploit the Markovian nature of the state sequence \cite{Godsill2004} are of no help, because past changepoints are not independent of future observations (i.e. $p(\theta_{n}|\theta_{n}^{+}, y_{1:N}) \ne p(\theta_{n}|\theta_{n}^{+}, y_{1:n}))$. However, when the state dynamics are linear-Gaussian conditional on the changepoint sequence, it is possible split the dependence on the observations into past and future by introducing the current state as an additional variable. This trick was used in \cite{Sarkka2012} in the derivation of the Rao-Blackwellised particle filter for fixed rate conditionally linear-Gaussian models.
%
\begin{IEEEeqnarray}{rCl}
 \IEEEeqnarraymulticol{3}{l}{p(\theta_{n}|\theta_{n}^+, y_{1:N})} \nonumber \\
\qquad & \propto & p(\theta_{n}, \theta_{n}^+| y_{1:N}) \nonumber  \\
       & =       & \int p(x_n, \theta_{n}, \theta_{n}^+| y_{1:N}) dx_n \nonumber  \\
       & \propto & \int p(y_{n+1:N}|x_n, \theta_{n}, \theta_{n}^+, y_{1:n}) p(x_n, \theta_{n}, \theta_{n}^+| y_{1:n}) dx_n \nonumber \\
       & = & \int p(y_{n+1:N}|x_n, \theta_{n}^+) p(x_n|\theta_{n}, y_{1:n}) dx_n \nonumber \\
       &   & \times p(\theta_{n}^+|\theta_{n}) p(\theta_{n}|y_{1:n})
\end{IEEEeqnarray}

Finally, the particle approximation is substituted for the filtering distribution.
%
\begin{IEEEeqnarray}{rCl}
\hat{p}(\theta_{n}|\theta_{n}^+, y_{1:N}) & = & \sum_i \tilde{w}_{n}^{(i)} \delta_{\theta_{n}^{(i)}}(\theta_{n})  \label{eq:rb-vrps_back_cond}
\end{IEEEeqnarray}

where the backwards conditional weights are given by
%
\begin{IEEEeqnarray}{rCl}
 \tilde{w}_n & \propto & w_n \int p(y_{n+1:N}|x_n, \theta_{n}^+) \nonumber \\
             &         & \times p(x_n|\theta_{n}^{(i)}, y_{1:n}) dx_n p(\theta_{n}^+|\theta_{n}^{(i)}) \label{eq:rb-vrps_back_cond_weight}
\end{IEEEeqnarray}

As before, normalisation is enforced by scaling the weights so that they sum to $1$.

The changepoint transition density may be expressed as,
%
\begin{IEEEeqnarray}{rCl}
 p(\theta_{n}^+|\theta_{n}) &=      & p(\tau_{K_n+1:K}, u_{K_n+1:K}|\tau_{K_n}, u_{K_n}, \tau_{K_n+1}>t_n) \nonumber \\
                                    &\propto& p(\tau_{K_n+1}, u_{K_n+1}|\tau_{K_n}, u_{K_n}, \tau_{K_n+1}>t_n)     .
\end{IEEEeqnarray}

The integral in~(\ref{eq:rb-vrps_back_cond_weight}) contains two terms involving the current state, $x_n$. The first is the familiar state posterior generated by the Kalman filter using (\ref{eq:kf_predict_start}--\ref{eq:kf_update_stop}).
%
\begin{IEEEeqnarray}{rCl}
p(x_n|\theta_{n}^{(i)}, y_{1:n}) & = & \mathcal{N}(x_n|m_n^{(i)}, P_n^{(i)})
\end{IEEEeqnarray}

The mean and covariance of this distribution will have been calculated during the filtering stage, and can be stored for use now in the smoother.

The second state term in (\ref{eq:rb-vrps_back_cond_weight}) is the likelihood, $p(y_{n+1:N}|x_n, \tilde{\theta}_{n}^+)$. This may be considered to be an improper density over $x_n$, and may be calculated analytically using a backwards Kalman filter, in a similar manner to that used in the two-filter smoother \cite{Fraser1969,Kitagawa1994,Sarkka2012,Gelb1974}. Such a backwards Kalman filter uses the following recursions. Derivations may be found in the aforesaid references.
%
\begin{IEEEeqnarray}{rCl}
 p(y_{n+1:N}|x_n, \theta_{n}^+) & \propto & \mathcal{N}(x_n|\tilde{m}_n^-, \tilde{P}_n^-) \\
 p(y_{n:N}|x_n, \theta_{n}^+) & \propto & \mathcal{N}(x_n|\tilde{m}_n, \tilde{P}_n)
\end{IEEEeqnarray}
%
\begin{IEEEeqnarray}{rCl}
 \tilde{m}_n^- & = & A_{n+1}^{-1} \tilde{m}_{n+1} \label{eq:backward_kf_predict_start} \\
 \tilde{P}_n^- & = & A_{n+1}^{-1} (\tilde{P}_{n+1} + Q_{n+1}) A_{n+1}^{-T} \label{eq:backward_kf_predict_stop} \\
 \tilde{\mu}_n & = & C_n \tilde{m}_n^- \label{eq:backward_kf_update_start} \\
 \tilde{S}_n   & = & C_n \tilde{P}_n^- C_n^T + R_n \\
 \tilde{K}_n   & = & \tilde{P}_n^- C_n^T \tilde{S}_n^{-1} \\
 \tilde{m}_n   & = & \tilde{m}_n^- + \tilde{K}_n (y_n - \tilde{\mu}_n) \\
 \tilde{P}_n   & = & \tilde{P}_n^- - \tilde{K}_n \tilde{S}_n \tilde{K}_n^T \label{eq:backward_kf_update_stop}
\end{IEEEeqnarray}

Exact methods for initialising this recursion are discussed in \cite{Kitagawa1994}. However, it is often sufficient to use an approximation, for example $\tilde{m}_N^{(i)} = m_N^{(i)}$ and $\tilde{P}_N^{(i)} = P_N^{(i)}$.

Substituting into (\ref{eq:rb-vrps_back_cond_weight}), the backwards conditional weights are given by,
%
\begin{equation}
 \tilde{w}_n \propto w_n p(\theta_{n}^+|\theta_{n}^{(i)}) \mathcal{N}(\tilde{m}_n^-|m_n, \tilde{P}_n^- + P_n)     .
\label{eq:rb-vrps_back_cond_weight2}
\end{equation}

Using these weights, a sample of $\theta_{n}$ may be drawn from the particle distribution of (\ref{eq:rb-vrps_back_cond}), completing the smoothing algorithm. Once sampling has progressed backwards from $n=N \dots 1$, a particle from the smoothing distribution will have been generated. This procedure may then be repeated until sufficient particles have been obtained. The algorithm is summarised in Fig.~\ref{alg:RBVRPS}.

\begin{figure}
\fbox{\parbox{\columnwidth}{
\begin{algorithmic}[1]
\linespread{1.5} \selectfont
  \STATE Run Rao-Blackwellised variable rate particle filter to approximate $p(\theta_{n}|y_{1:n})$ with weighted particles $\{\theta_{n}^{(i)}, w_{n}^{(i)}\}$ and $\{p(x_n|\theta_{n}^{(i)},y_{1:n})\}$ as normal distributions with moments $\{m_{n}^{(i)}\}$ and $\{P_{n}^{(i)}\}$. Store all results.
  \FOR{$i=1 \dots N_S$}
  	\STATE Initialise particle using $\theta^{(i)} \sim \sum_j w_N^{(j)} \delta_{\theta^{(j)}}(\theta)$.
    \STATE Initialise sufficient statistics $\tilde{m}_N^{(i)}$ and $\tilde{P}_N^{(i)}$ (see text).
    \FOR{$n=N-1 \dots 1$}
      \STATE Discard $\theta_{n}^{(i)}$.
      \STATE Predict state mean and covariance $\tilde{m}_n^{-(i)}$ and $\tilde{P}_n^{-(i)}$ using (\ref{eq:backward_kf_predict_start}) to (\ref{eq:backward_kf_predict_stop}).
      \FOR{$j=1 \dots N_P$}
	      \STATE Calculate weight $\tilde{w}_n^{(j)}$ using (\ref{eq:rb-vrps_back_cond_weight2}).
      \ENDFOR
      \STATE Sample $\theta_{n}^{(i)} \sim \sum_j \tilde{w}_n^{(j)} \delta_{\theta_{n}^{(j)}}(\theta_{n})$.
      \STATE Join $\theta^{(i)} \gets \theta_{n}^{(i)} \cup \theta_{n}^{+(i)}$.
      \STATE Update state mean and covariance $\tilde{m}_n^{(i)}$ and $\tilde{P}_n^{(i)}$ using \ref{eq:backward_kf_update_start} to \ref{eq:backward_kf_update_stop}.
    \ENDFOR
  \ENDFOR
\end{algorithmic}
}}
\caption{Rao-Blackwellised Variable Rate Particle Smoother}
\label{alg:RBVRPS}
\end{figure}

The algorithmic complexity of this variable rate particle smoother for conditionally linear-Gaussian models is $O(N_F \times N_S \times N)$. It is possible to reduce this by using an MCMC sampling scheme in the style of \cite{Bunch2012}, which avoids the necessity of calculating the sampling weights for every filter particle.



\subsection{Conditionally Deterministic Smoothing} \label{sec:pd-vrps}

In a conditionally deterministic system, the entire continuous time state trajectory, $x(t)$, is a function of the changepoint sequence $\theta$ and the initial state, $x_0$. When the changepoint sequence is split into past, $\theta_n$, and future $\theta_n^+$, and the past is altered, this will alter the state trajectory in the future. This is undesirable, as each sampling operation will require the recalculation of state values and observations likelihoods for all future observation times.

In order to achieve conditional independence between past and future observations, consider the augmented changepoint sequence, $\tilde{\theta} = \{\tau_{0:K}, u_{0:K}, x_{0:K}\}$ ($\tilde{\theta}_n$ and $\tilde{\theta}_n^+$ defined in the same manner as before). The changepoint state values, $x_{0:K}$ may be calculated deterministically from $\theta$ for each particle. The smoother is then formulated by factorising the augmented sequence posterior distribution as before,
%
\begin{IEEEeqnarray}{rCl}
 p(\tilde{\theta}|y_{1:N}) = p(\tilde{\theta_{n}}^{+}|y_{1:N}) p(\tilde{\theta}_{n}|\tilde{\theta}_{n}^{+}, y_{1:N})     .
\end{IEEEeqnarray}

Again, this suggests a backwards sequential sampling algorithm for smoothing. The conditional term may be expanded as,
%
\begin{IEEEeqnarray}{rCl}
p(\tilde{\theta}_{n}|\tilde{\theta}_{n}^{+}, y_{1:N}) & \propto & p(y_{n+1:N}|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}) \nonumber \\
& & \times p(\tilde{\theta}_{n}^{+}|\tilde{\theta}_{n}) p(\tilde{\theta}_{n}|y_{1:n})    .
\end{IEEEeqnarray}

This presents a problem. We cannot directly substitute the particle approximation for the filtering distribution because the transition density term for the augmented sequences is given by,
%
\begin{IEEEeqnarray}{rCl}
p(\tilde{\theta}_{n}^+ | \tilde{\theta}_{n}) & \propto & p(\tau_{K_n+1}, u_{K_n+1}| \tau_{K_n}, u_{K_n}) \nonumber \\
 & & \times \delta_{f(x_{K_n}, u_{K_n}, \tau_{K_n}, \tau_{K_n+1})}(x_{K_n+1}),
\end{IEEEeqnarray}

which will be $0$ for almost all filtering particles. Intuitively, we are trying to join two deterministic state trajectories together, but they do not meet up in the middle.

The solution to this problem is provided by an idea from the Sequential Monte Carlo (SMC) samplers of \cite{DelMoral2006}. Rather than sampling $p(\tilde{\theta}_{n}|\tilde{\theta}_{n}^{+}, y_{1:N})$ directly, a value of $\tilde{\theta}_{n}$ is proposed from the filtering particles, after which a replacement, $u_{K_n}'$, is proposed for the existing final changepoint parameter, with a value chosen such that the past and future paths meet up. The modified sequence is denoted $\tilde{\theta}_{n}'$. Such a proposal density may be written as,
%
\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{p(\tilde{\theta}_{n}|y_{1:n}) q(u_{K_n}|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N})} \nonumber \\
 \qquad & \propto & p(y_{1:n}|\tilde{\theta}_{n}) p(\tilde{\theta}_{n}) q(u_{K_n}'|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N}) \label{eq:pd-vrps_proposal}     .
\end{IEEEeqnarray}

The target distribution is augmented by introduction of an artificial density to cover the new changepoint sequence and the discarded parameter.
%
\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{ p(\tilde{\theta}_{n}'|\tilde{\theta}_{n}^{+}, y_{1:N}) L(u_{K_n}|\tilde{\theta}_{n}', \tilde{\theta}_{n}^{+}, y_{1:N}) } \nonumber \\
 & \propto & p(y_{1:N}|\tilde{\theta}_{n}', \tilde{\theta}_{n}^+) p(\tilde{\theta}_{n}^{+}|\tilde{\theta}_{n}') p(\tilde{\theta}_{n}') L(u_{K_n}|\tilde{\theta}_{n}', \tilde{\theta}_{n}^{+}, y_{1:N})  \label{eq:pd-vrps_target}     .
\end{IEEEeqnarray}

Clearly this new target distribution admits the desired posterior as a marginal.

For this method to work, a new condition must be imposed on the state dynamics. For any pair of adjacent changepoints, $(\tau_k,x_k)$, and $(\tau_{k+1},x_{k+1})$ it must be possible to calculate a parameter value which results in the transition from the former to the latter. As a rule of thumb, this requires the number of dimensions of $u_k$ to be greater or equal to the number of dimensions of $x_k$.

The augmented target distribution may be sampled using Markov chain Monte Carlo (MCMC) \cite{Gilks1996}, in a similar manner to the fixed rate smoother of \cite{Bunch2012}. Metropolis-Hastings (MH) steps are conducted to draw samples, $\{\tilde{\theta}_{n}, u_{K_n}'\}$, from the target distribution by sampling the proposal and accepting the new values with a given probability.      % (IS could be used, but this would require resampling steps, which would lead to a loss of path-space diversity)

The ratio of target (\ref{eq:pd-vrps_target}) and proposal (\ref{eq:pd-vrps_proposal}) densities is given by,
%
\begin{IEEEeqnarray}{rCl}
\beta_n & \propto & \frac{ p(y_{r_n^-:r_n^+}|\tilde{\theta}_{n}') }{ p(y_{r_n^-:n}|\tilde{\theta}_{n}) } \times \frac{ p(u_{K_n}'|\tau_{K_n}, \tau_{K_n-1}, u_{K_n-1}) }{ p(u_{K_n}|\tau_{K_n}, \tau_{K_n-1}, u_{K_n-1}) } \nonumber \\
  & & \times p(\tilde{\theta}_{n}^{+}|\tilde{\theta}_{n}') \times \frac{ L(u_{K_n}|\tilde{\theta}_{n}', \tilde{\theta}_{n}^{+}, y_{1:N}) }{ q(u_{K_n}'|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N}) } \label{eq:pd-vrps_tpr}    ,
\end{IEEEeqnarray}

where $r_n^- = \min( m : t_m > \tau_{K_n} )$ and $r_n^+ = \max( m : t_m < \tau_{K_n+1} )$ are the indexes of the earliest and latest observations to fall between the changepoints each side of $t_n$.

%The transition density term will include a delta function with unit probability mass at the point for which the past and future state trajectories match up.

%\begin{IEEEeqnarray}{rCl}
%\IEEEeqnarraymulticol{3}{l}{p(\tilde{\theta}_{n}^{+}|\tilde{\theta}_{n}') \propto p(u_{K_n+1}|\tau_{K_n+1}, \tau_{K_n}, u_{K_n})} \nonumber \\ \times p(\tau_{K_n+1}|\tau_{K_n}, u_{K_n}) \delta_{f(x_{K_n}, v_{K_n}, \tau_{K_n}, \tau_{K_n+1})}(x_{K_n+1})
%\end{IEEEeqnarray}

The proposal density $q(u_{K_n}'|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N})$ is constructed so as to be non-zero only where $p(\tilde{\theta}_{n}^{+}|\tilde{\theta}_{n}')$ is non-zero. This may require it to be a delta function if there is only one feasible value. The artificial conditional term, $L(u_{K_n}|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N})$, may be any arbitrary density, but the simplest choice is simply as a uniform distribution so that it cancels out in the MH acceptance probability. The remaining terms are likelihoods and parameter transition density terms, defined by the system equations.

If $\beta_n^{(m-1)}$ is the target-proposal ratio for the current state in the chain, and $\beta_n^*$ that for the new state, then the acceptance probability is given by,
%
\begin{IEEEeqnarray}{rCl}
\alpha_n^{(m)} = \min \left( 1, \frac{\beta_n^*}{\beta_n^{(m-1)}} \right) \label{eq:pd-vrps_ap}     .
\end{IEEEeqnarray}

Each Markov chain may be initialised with the output from the previous stage. This value is itself a particle from the target distribution (albeit one from an approximation with poor diversity), meaning that no burn-in period is required.

The algorithm is summarised in Fig.~\ref{alg:VRPS}.

\begin{figure}
\fbox{\parbox{\columnwidth}{
\begin{algorithmic}[1]
\linespread{1.5} \selectfont
  \STATE Run variable rate particle filter to approximate $p(\tilde{\theta}_{n}|y_{1:n})$ with weighted particles $\{\tilde{\theta}_{n}^{(i)}, w_{n}^{(i)}\}$. Store all results.
  \FOR{$i=1 \dots N_S$}
  	\STATE Initialise particle using $\tilde{\theta}^{(i)} \sim \sum_j w_N^{(j)} \delta_{\tilde{\theta}^{(j)}}(\tilde{\theta})$.
    \FOR{$n=N \dots 1$}
      \STATE Initialise chain with $\tilde{\theta}_n^{(i)(0)} \gets \tilde{\theta}_n^{(i)}$.
      \FOR{$m=1 \dots M$}
        \STATE Propose a new history $\tilde{\theta}_n^{(i)*} \sim \sum_j w_n^{(j)} \delta_{\tilde{\theta}_{n}^{(j)}}(\tilde{\theta}_{n})$.
        \STATE Propose a parameter $u_{K_n}'^* \sim q(u_{K_n}|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N})$.
        \STATE Replace $u_{K_n}^*$ with $u_{K_n}'^*$ to form $\tilde{\theta}_n'^{(i)*}$.
        \STATE Calculate $\alpha_n^{(m)}$ using (\ref{eq:pd-vrps_tpr}) and (\ref{eq:pd-vrps_ap}).
        \STATE With probability $\alpha_n^{(m)}$, $\tilde{\theta}_n^{(i)(m)} \gets \tilde{\theta}_n^{(i)*}$. \\ Otherwise, $\tilde{\theta}_n^{(i)(m)} \gets \tilde{\theta}_n^{(i)(m-1)}$.
      \ENDFOR
      \STATE Store final sample $\tilde{\theta}_n^{(i)} \gets \tilde{\theta}_n^{(i)(M)}$.
    \ENDFOR
  \ENDFOR
\end{algorithmic}
}}
\caption{MCMC piecewise-deterministic variable rate particle smoother}
\label{alg:VRPS}
\end{figure}

The number of MH steps, $M$, at each observation time, $n$, allows a trade-off of performance against time. Larger values of $M$ will ensure more unique samples in the smoothing approximation, but will also take longer to execute. See \cite{Bunch2012} for analysis of this trade-off on a fixed rate model. In the simulations discussed in this report, $M=1$ was used throughout.



\section{Simulations} \label{sec:simulations}

The smoothers and the final step of the filters each produce a particle approximation to the changepoint sequence posterior, $p(\theta|y_{1:N})$. Calculating a single estimator from these is no simple task. Each particle consists of a list of changepoint times and parameters, and there is no obvious way to take an average over the set to produce a single estimate. Furthermore, if a best estimate could be calculated, it is not trivial to define a distance metric between the estimated and true sequences to assess relative accuracy.

Comparisons of accuracy are most easily conducted by comparing state estimates. These can be calculated by simply taking a mean of the particle values (using the Gaussian means for the linear-Gaussian case). The accuracy is then assessed by comparing the root mean squared error (RMSE) of the resulting estimators.

In the following examples, we compare the state estimates from the VRPF, the ``filter-smoother'' and the VRPS. Filter-smoother estimates use the particle approximation from the final step of the VRPF for the changepoint distribution. In the linear-Gaussian case, an RTS smoother is used to find the state posterior distribution for each particle, $p(x_n|\theta^{(i)}, y_{1:N})$, from which state estimates are derived.

In addition, the benefit of employing a smoothing algorithm is that it ensures a more diverse particle representation of the posterior state distribution. To demonstrate this effect, the number of unique state estimates is plotted over time in the following examples.



\subsection{Conditionally Linear-Gaussian Model} \label{sec:finance}

The Rao-Blackwellised VRPS algorithm was tested on the financial time series model of \cite{Godsill2007a,Christensen2012}, in which prices of an asset are treated as noisy observations of a latent state, which evolves according to a drift-diffusion with occasional jumps.

The latent state is a vector with two elements, the underlying value of the asset, and the trend followed by this value.
%
\begin{equation}
 \mathbf{x}(t) = [ x(t), \dot{x}(t)]^T
\end{equation}

This evolves continuously according to a jump-diffusion model:
%
\begin{IEEEeqnarray}{c}
 d\mathbf{x}(t) = \begin{bmatrix}0 & 1 \\ 0 & -\lambda \end{bmatrix} \mathbf{x}(t) dt + \begin{bmatrix}0 \\ \sigma \end{bmatrix} d\beta(t) + d\mathbf{J}(t)
\end{IEEEeqnarray}

where $\lambda$ introduces a mean regression effect on the trend and $\mathbf{\beta}(t)$ is standard Brownian motion (with unit diffusion constant). The jump term, $d\mathbf{J}(t)$, is zero everywhere except where jumps occur.
%
\begin{IEEEeqnarray}{rCl}
 d\mathbf{J}(t) & = & \begin{cases} \mathbf{J}_k & t \in \{\tau_k\} \\ 0 & \text{elsewhere} \end{cases} \\
 \mathbf{J}_k  & \sim & \mathcal{N}(\mathbf{J}_k| \mathbf{0}, Q_{J,u_k})
\end{IEEEeqnarray}

Jumps occur at a random set of times, $\{\tau_k\}$, and are one of two types: value jumps, indicated by $u_k = 1$, and trend jumps, indicated by $u_k=2$.

%The jump covariance matrices are,
%%
%\begin{IEEEeqnarray}{c}
%Q_{J,u_k} = \begin{cases} \begin{bmatrix}\sigma_{J1}^2 & 0 \\ 0 & 0 \end{bmatrix} & u_k = 1 \\
%                          \begin{bmatrix}0 & 0 \\ 0 & \sigma_{J2}^2 \end{bmatrix} & u_k = 2  \end{cases}   .
%\end{IEEEeqnarray}

This model may be discretised at the observation times using standard methods (see \cite{Godsill2007a,Christensen2012,Grewal2002}), leading to,
%
%Assuming observations of value only and Gaussian observation noise with standard deviation $\sigma_y^2$, the resulting discrete time dynamics are described by the following equations:% (see appendix \ref{app:model_discretisation}):
%
\begin{IEEEeqnarray}{rCl}
 \mathbf{x}_n &=& A \mathbf{x}_{n-1} + \mathbf{w}_n \\
 y_n          &=& C \mathbf{x}_{n} + v_n
\end{IEEEeqnarray}

where the $\mathbf{w}_n$ and $v_n$ are Gaussian random variables with covariance matrixes $Q_n$ and $R$ respectively.% The time between observations times is denotes $\Delta t = t_{n} - t_{n-1}$.
%
%\begin{IEEEeqnarray}{rCl}
% A     &=& \begin{bmatrix}1 & \frac{1}{\lambda}(1-e^{(-\lambda \Delta t)} \\ 0 & e^{(-\lambda \Delta t)}\end{bmatrix} \\
% C     &=& \begin{bmatrix}1 & 0\end{bmatrix}
%\end{IEEEeqnarray}
%\begin{IEEEeqnarray}{rCl}
% Q_n   &=& \begin{cases}Q_{D} + Q_{J,u_k} & \exists k : \tau_k \in [t_{n-1},t_n]\\
%                        Q_{D}             & \text{otherwise} \end{cases} \\
% Q_{D} &=& \frac{\sigma^2}{2 \lambda}\begin{bmatrix} q_1 & q_2 \\ q_2 & q_3\end{bmatrix} \\
% q_1   &=& \frac{1}{\lambda^2}(2 \lambda \Delta t - (3 - e^{(-\lambda \Delta t)})(1 - e^{(-\lambda \Delta t)})~) \\
% q_2   &=& \frac{1}{\lambda} (1-e^{(-\lambda \Delta t)})^2 \\
% q_3   &=& 1-e^{(-2 \lambda \Delta t)} \\
% R     &=& [\sigma_y^2]
%\end{IEEEeqnarray}

The times between changepoints were assumed to be exponentially distributed, with equal probability of value and trend jumps.
%
%\begin{IEEEeqnarray}{rCl}
% \IEEEeqnarraymulticol{3}{l}{p(\tau_k, u_k|\tau_{k-1}, u_{k-1}) = P(u_k) p(\tau_k|\tau_{k-1})} \\
% p(\tau_k|\tau_{k-1})               &=& \begin{cases}\frac{1}{\alpha} \exp ( \alpha (\tau_k-\tau_{k-1}) ) & \tau_k>\tau_{k-1} \\
%                                                     0 & \tau_k < \tau_{k-1} \end{cases} \\
% P(u_k)                             &=& \begin{cases}0.5 & u_k = 1 \\ 0.5 & u_k = 2\end{cases}
%\end{IEEEeqnarray}

The algorithms were tested on artificial data simulated from this model. Observations were made on a regular time grid with a spacing of $0.0017s$. The decay constant for the distribution of inter-changepoint times is 20, and the trend mean-reversion coefficient is 5. The diffusion constant is 0.05 and the observation noise standard deviation 0.001. The jump standard deviations are 0.005 and 0.05 respectively for value and trend.

%The following parameters were used: $\Delta t = 0.0017$, $N = 1000$, $\alpha = 20$, $\lambda = 5$, $\sigma = 0.05$, $\sigma_{J1} = 0.005$, $\sigma_{J2} = 0.05$, $\sigma_{y} = 0.001$.

The filter used $N_P = 100$ particles, and the smoother resampled $N_S = 100$ sequences. Bootstrap proposals were used for the filter. An example realisation simulated from the model is shown in figure~\ref{fig:example_data}. The trend estimates produced by the filter-smoother and VRPS are shown in figure~\ref{fig:example_state} (the equivalent graphs for value estimates are not particularly informative, as this quantity is observed).

\begin{figure}[!t]
\centering
\includegraphics[width=0.9\columnwidth]{example_data.pdf}
\caption{An example simulated data set, showing value (top) and trend (bottom). Value observations are overlayed. Jump times are shown as dotted vertical lines.}
\label{fig:example_data}
\end{figure}

\begin{figure}[!t]
\centering
\subfloat[]{\includegraphics[width=0.95\columnwidth]{example_filtersmoother_state.pdf}} \\
\subfloat[]{\includegraphics[width=0.95\columnwidth]{example_smoother_state.pdf}}
\caption{Trend estimates from (a) the filter-smoother and (b) the VRPS. Solid lines show means of each particle. Dashed lines show mean $\pm$2 standard deviations.}
\label{fig:example_state}
\end{figure}

%For a first, qualitative comparison of the changepoint sequence distributions, it is possible to generate kernel density estimates for the changepoint times. These are constructed by simply adding a (unit amplitude) Gaussian kernel for each changepoint present in each particle and scaling by the number of particles. The resulting function provides an approximate measure of the likelihood of finding a jump at a given time. These are shown in figure~\ref{fig:example_kdest} for the example data set.

%\begin{figure}[!t]
%\centering
%\subfloat[]{\includegraphics[width=0.95\columnwidth]{example_filter_kdest.pdf}} \\
%\subfloat[]{\includegraphics[width=0.95\columnwidth]{example_smoother_kdest.pdf}}
%\caption{Filter (a) and smoother (b) kernel density estimates for value (top) and trend (bottom) jump times. Correct times overlayed as dotted vertical lines.}
%\label{fig:example_kdest}
%\end{figure}

%It is immediately apparent that the approximation produced by the filter lacks diversity. The jump time kernel density estimate comprises peaks with magnitude $1$, with regions of $0$ between. This is a result of every particle containing an almost identical list of changepoints, as a result of resampling. In contrast, the smoother is clearly providing a less degenerate particle representation, and generally contains larger kernel density peaks at the times of larger jumps. Furthermore, the kernel density for the trend jump times contains broader peaks, capturing the fact that because the trend is not observed directly, the jumps are harder to localise precisely.

%A further comparison of the algorithms is possible via the state estimates they generate. Here we can compare three options: the filtering results, using the VRPF and a Kalman filter for the state estimates; the filter-smoother results, using the final VRPF approximation for the changepoint sequence and a Rauch-Tung-Striebel (RTS) smoother for the state estimates; and the full smoothing results, using the VRPS followed by an RTS smoother. For the example data set, the trend estimates are shown in figure~\ref{fig:example_state} (The estimates of value are less informative, as this quantity is observed). Again, the improved particle diversity of the smoother is apparent.

%\begin{figure}[!t]
%\centering
%\subfloat[]{\includegraphics[width=0.95\columnwidth]{example_filter_state.pdf}} \\
%\subfloat[]{\includegraphics[width=0.95\columnwidth]{example_filtersmoother_state.pdf}} \\
%\subfloat[]{\includegraphics[width=0.95\columnwidth]{example_smoother_state.pdf}}
%\caption{Trend estimates using RBVRPF + Kalman filter (a) RBVRPF + RTS smoother (b) and RBVRPS + RTS smoother. Solid lines show means of each particle. Dashed lines show mean $\pm$2 standard deviations.}
%\label{fig:example_state}
%\end{figure}

%For a quantitative comparison, the algorithms were tested on $10$ realisations from the model, each of $1000$ time steps, and the following statistics were calculated for each:
%\begin{itemize}
%	\item The number of unique changepoint sequences. This is a measure of particle diversity of the approximation.
%	\item The number of unique changepoint times. Another measure of particle diversity.
%	%\item The optimal sub-pattern assignment (OSPA) distance between the maximum a posteriori (MAP) changepoint sequence and the true sequence. The OSPA is a concept from multiple target tracking introduced in \cite{Schuhmacher2008} to measure the distance between sets of points of varying cardinality. It is thus well suited to measuring the error between changepoint sequences of varying length. For each approximation, the sequence from the MAP particle was used as a point estimate.
%	%\item The root-mean-square error (RMSE) of the MAP state estimate. The MAP state estimate is taken to be the Gaussian mean of the conditional state distribution, from the Kalman smoother or RTS, selected from the particle with the highest posterior probability.
%	\item The root-mean-square error (RMSE) of the mean state estimate. The mean state estimate is the average of the Gaussian means from all the particles.
%\end{itemize}

%Note that the MAP particle may be found by calculating the posterior probability of each. The terms required for this calculation will already have been evaluated during the filtering procedure.

%\begin{IEEEeqnarray}{rCl}
% p(\theta|y_{1:N}) & \propto & p(y_{1:N}|\theta) p(\theta) \nonumber \\
%                         &         & S(\tau_K, T) \prod_{k=1}^K p(u_k) p(\tau_k|\tau_{k-1}) \prod_{n=1}^{N} p(y_n|\theta, y_{1:n-1})
%\end{IEEEeqnarray}

Performance was evaluated by testing on 10 scenarios, each with 1000 observations. At each observation time, an estimate of the value and trend is made by taking the average of Gaussian means generated by an RTS smoother for each particle. The resulting root mean square errors (RMSEs) are displayed in table~\ref{tab:finance_state_performance}, demonstrating an improvement in accuracy from the smoother.

\begin{table}%
\caption{State estimation performance.}
\label{tab:finance_state_performance}
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|c|c|c|c|}
\hline
 &\raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{1.5cm}{\centering VRPF}} & \raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{1.5cm}{\centering Filter-smoother}} & \raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{1.5cm}{\centering VRPS}} \\
\hline \hline
\raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{2cm}{\centering mean value estimate RMSE}}   & $5.31 \times 10^{-4}$ & $4.48 \times 10^{-4}$ & $4.16 \times 10^{-4}$ \\
\hline
\raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{2cm}{\centering mean trend estimate RMSE}}   & $2.56 \times 10^{-2}$ & $1.79 \times 10^{-2}$ & $1.49 \times 10^{-2}$ \\
\hline
\end{tabular}
\end{table}


%The results are shown in tables~\ref{tab:finance_cp_performance} and ~\ref{tab:finance_state_performance}.% The OSPA parameters are: exponent $p=1$, threshold $c=0.01$.

%\begin{table}%
%\caption{Changepoint sequence estimation performance.}
%\label{tab:finance_cp_performance}
%\centering
%\renewcommand{\arraystretch}{1.5}
%\begin{tabular}{|c|c|c|}
%\hline
% & RBVRPF & RBVRPS \\
%\hline \hline
%mean unique no. sequences   & 7.8      & 100       \\
%\hline
%mean unique no. jump times  & 47.8     & 1076.7    \\
%%MAP sequence OSPA    & $5.36 \times 10^{-3}$ & $4.98 \times 10^{-3}$  \\
%\hline
%\end{tabular}
%\end{table}

%\begin{table}%
%\caption{State estimation performance.}
%\label{tab:finance_state_performance}
%\centering
%\renewcommand{\arraystretch}{1.5}
%\begin{tabular}{|c|c|c|c|}
%\hline
% &\raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{1.5cm}{\centering RBVRPF and KF}} & \raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{1.5cm}{\centering RBVRPF and RTS}} & \raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{1.5cm}{\centering RBVRPS and RTS}} \\
%% & \begin{minipage}[c]{1.5cm}\centering RBVRPF + KF\end{minipage} & \begin{minipage}[c]{1.5cm}\centering RBVRPF + RTS\end{minipage} & \begin{minipage}[c]{1.5cm}\centering RBVRPS + RTS\end{minipage} \\
%\hline \hline
%\raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{2cm}{\centering mean value estimate RMSE}}   & $5.31 \times 10^{-4}$ & $4.48 \times 10^{-4}$ & $4.16 \times 10^{-4}$ \\
%\hline
%\raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{2cm}{\centering mean trend estimate RMSE}}   & $2.56 \times 10^{-2}$ & $1.79 \times 10^{-2}$ & $1.49 \times 10^{-2}$ \\
%%MAP value estimate RMSE    & $5.98 \times 10^{-4}$ & $4.48 \times 10^{-4}$ & $4.49 \times 10^{-4}$ \\
%%MAP trend estimate RMSE    & $3.13 \times 10^{-2}$ & $1.79 \times 10^{-2}$ & $1.74 \times 10^{-2}$ \\
%\hline
%\end{tabular}
%\end{table}

%The new RBVRPS algorithm outperforms the filter in terms of both state estimation accuracy and particle diversity.

%\begin{meta}
%Another interesting question is how the posterior distribution over the number of changepoints is expected to behave. The prior is poisson distributed with mean $\alpha T$. The means of both the filter and smoother particle posterior are consistently greater than the true number (by about 50\%). Is this expected and why?
%\end{meta}

%Finally, we demonstrate the algorithms on a real financial data set, 1000 data points representing 1.7s of USD-GBP foreign exchange rate data from April 2008, using the same parameters as for the previous simulations. The data shown in Fig.~\ref{fig:fx_results}, along with jump time kernel density estimates from the filter and smoother. In this example, there is no ground truth against which to judge the results. However, the smoother does a pleasing job of estimating jump times in the same areas that one would if analysing the data ``by eye''. We submit this simply to illustrate the practical applications of the model and algorithm.

%\begin{figure}[!t]
%\centering
%\subfloat[]{\includegraphics[width=0.95\columnwidth]{fx_data.pdf}} \\
%\subfloat[]{\includegraphics[width=0.95\columnwidth]{fx_filter_kdest.pdf}} \\
%\subfloat[]{\includegraphics[width=0.95\columnwidth]{fx_smoother_kdest.pdf}}
%\caption{Foreign exchange data (a), along with filter (b) and smoother (c) kernel density estimates for the state and trend jump times.}
%\label{fig:fx_results}
%\end{figure}

The mean number of unique particle estimates at each time step is shown in Fig.~\ref{fig:finance_unique_particles}. This illustrates the main advantage of the smoother algorithm --- the increased number of unique particles in the approximation means a better characterisation of the posterior changepoint distribution.

\begin{figure}[!t]
\centering
\includegraphics[width=0.75\columnwidth]{finance_unique_particles.pdf}
\caption{Mean number of unique particles in the filter-smoother (dashed) and smoother (solid) estimates.}
\label{fig:finance_unique_particles}
\end{figure}



\subsection{Conditionally Deterministic Model}

The piecewise-deterministic VRPS was tested using a 2-dimensional dynamic model for manoeuvring vehicles \cite{Bunch2012a}. The target is modelled as a particle subject to perpendicular forces tangential and normal to the direction of motion. These forces are held constant between changepoint times, $\tau_{1:K}$, which represent the beginnings and ends of manoeuvres.

The state vector consists of cartesian position, $x(t)$ and $y(t)$, plus bearing, $\psi(t)$, and speed, $\dot{s}(t)$.
%
\begin{equation}
\mathbf{x}(t) = [x(t), y(t), \psi(t), \dot{s}(t)]^T
\end{equation}

In addition to the tangential and normal accelerations, $a_{T,k}$ and $a_{N,k}$, we introduce two linear velocity terms, $d_{X,k}$ and $d_{Y,k}$. Without these, the model could not be used for smoothing, because for an arbitrary pair of adjacent changepoints ($\tau_{k}$, $\mathbf{x}_{k}$) and ($\tau_{k+1}$, $\mathbf{x}_{k+1}$), there would not in general be a pair of accelerations which achieved the required transition. These linear velocity terms may be considered to be merely relaxation terms, allowing arbitrary past and future trajectories to be joined, or they may represent real physical effects, such as wind (for aircraft) or currents (for boats). Together, these four variables make up the vector of motion parameters,
%
\begin{equation}
\mathbf{u}_k = [a_{T,k}, a_{N,k}, d_{X,k}, d_{Y,k}]^T
\end{equation}

The target dynamics are described by four differential equations.
%
\begin{IEEEeqnarray}{rCl}
\ddot{s}_t & = & a_{T,K(t)} \\
\dot{s}_t \dot{\psi}_t & = & a_{N,K(t)} \\
\dot{x}_t & = & \dot{s}_t \cos(\psi_t) + d_{X,K(t)} \\
\dot{y}_t & = & \dot{s}_t \sin(\psi_t) + d_{Y,K(t)}     .
\end{IEEEeqnarray}

Solving these yields the following state equations (where $\Delta\ t = t - \tau_{K(t)}$):
%The target dynamics are governed by the following state equations \cite{Bunch2012a} (where $\Delta\ t = t - \tau_{K(t)}$):
%
\begin{IEEEeqnarray}{rCl}
\dot{s}(t) & = & \dot{s}_{K(t)} + a_{T,k} \Delta t \label{eq:2D_ICmodel_start} \\
\psi(t) & = & \psi_{K(t)} + \frac{a_{N,k}}{a_{T,k}} \log \left( \frac{\dot{s}(t)}{\dot{s}_{K(t)}} \right)
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
x(t) & = & x_{K(t)} + d_{X,K(t)} \Delta t \\
     \IEEEeqnarraymulticol{3}{l}{ \quad + \: \frac{ \dot{s}(t)^2 }{ 4 a_{T,k}^2 + a_{N,k}^2 } \left[  a_{N,k} \sin(\psi(t)) + 2 a_{T,k} \cos(\psi(t))  \right]} \nonumber \\
     \IEEEeqnarraymulticol{3}{l}{ \quad - \: \frac{\dot{s}_{K(t)}^2}{4 a_{T,k}^2 + a_{N,k}^2} \left[  a_{N,k} \sin(\psi_{K(t)}) + 2 a_{T,k} \cos(\psi_{K(t)})  \right]} \nonumber
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
y(t) & = & y_{K(t)} + d_{Y,K(t)} \Delta t \\
     \IEEEeqnarraymulticol{3}{l}{ \quad + \: \frac{ \dot{s}(t)^2 }{ 4 a_{T,k}^2 + a_{N,k}^2 } \left[ -a_{N,k} \cos(\psi(t)) + 2 a_{T,k} \sin(\psi(t))  \right]} \nonumber \\
     \IEEEeqnarraymulticol{3}{l}{ \quad - \: \frac{\dot{s}_{K(t)}^2}{4 a_{T,k}^2 + a_{N,k}^2} \left[  -a_{N,k} \cos(\psi_{K(t)}) + 2 a_{T,k} \sin(\psi_{K(t)})  \right]} \nonumber      .
\end{IEEEeqnarray}

The changepoint motion parameters are assumed to be independent and zero-mean Gaussian distributed. The times between changepoints are modelled as gamma distributed. Observations are made via a radar-style bearing and range measurement model with Gaussian noise.

The filtering and smoothing algorithms were tested on artificial data simulated from the model. Observations were generated every $0.1$. The standard deviations of tangential and normal accelerations were set to $0.01$ and $1$ respectively, and those for the drift velocities to $1$. The parameters of the Gamma distribution for inter-changepoint times were $5$ and $1$ for the shape and scale respectively. Observation noise standard deviations were $0.1$ and $0.25^{\circ}$ respectively.

The filter and smoother were each used to generate $50$ particles, with the filter employing resample-move steps with proposals based on an unscented transform \cite{Julier2004} approximation to the optimal proposal density.

An example trajectory is shown in Fig.~\ref{fig:simulated_trajectory}, with the results of the VRPF and VRPS algorithms in Fig.\ref{fig:2D_particle_results}. The improved particle diversity achieved by the smoothing algorithm is apparent.

\begin{figure}[!t]
\centering
\includegraphics[width=0.9\columnwidth]{simulated_problem.pdf}
\caption{An example simulated data set, showing true position (dashed line), observations (dots) and changepoint positions (crosses). }
\label{fig:simulated_trajectory}
\end{figure}

\begin{figure}[!t]
\centering
\subfloat[]{\includegraphics[width=0.95\columnwidth]{2DFilter.pdf}} \\
\subfloat[]{\includegraphics[width=0.95\columnwidth]{2DSmoother.pdf}}
\caption{Filter (a) and smoother (b) particle estimates of position (solid lines), with particle changepoint positions (crosses). }
\label{fig:2D_particle_results}
\end{figure}

Performance was evaluated by testing on 10 scenarios, each with 500 observations. At each observation time, an estimate of the position and velocity is made by taking the average of values from the array of particles. The resulting root mean square errors (RMSEs) are displayed in table~\ref{tab:tracking_state_performance}, demonstrating an improvement in accuracy from the smoother. The smoother also provides a more accurate estimate of the number of changepoints in each test, with an average error of 0.6 compared to 2.0 from the final frame filter approximation.

The mean number of unique particle estimates at each time step is shown in Fig.~\ref{fig:tracking_unique_particles}. This illustrates the main advantage of the smoother algorithm --- the increased number of unique particles in the approximation means a better characterisation of the posterior changepoint distribution, allowing, for example, calculation of state covariance measures.

\begin{table}%
\caption{State estimation performance.}
\label{tab:tracking_state_performance}
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|c|c|c|c|}
\hline
 &\raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{1.5cm}{\centering VRPF}} & \raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{1.5cm}{\centering Filter-smoother}} & \raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{1.5cm}{\centering VRPS}} \\
% & \begin{minipage}[c]{1.5cm}\centering RBVRPF + KF\end{minipage} & \begin{minipage}[c]{1.5cm}\centering RBVRPF + RTS\end{minipage} & \begin{minipage}[c]{1.5cm}\centering RBVRPS + RTS\end{minipage} \\
\hline \hline
\raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{2cm}{\centering mean position estimate RMSE}} & 2.14 & 1.36 & 1.12 \\
\hline
\raisebox{0cm}[0.4cm][0.3cm]{\parbox[c]{2cm}{\centering mean velocity estimate RMSE}} & 1.89 & 1.03 & 0.85 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[!t]
\centering
\includegraphics[width=0.75\columnwidth]{tracking_unique_particles.pdf}
\caption{Mean number of unique particles in the final filter (dashed) and smoother (solid) estimates.}
\label{fig:tracking_unique_particles}
\end{figure}



\section{Conclusions}

New smoothing algorithms have been introduced for variable rate models which have either linear-Gaussian or deterministic dynamics conditional on a set of unknown changepoints. For the linear-Gaussian case, the algorithm employs Rao-Blackwellisation, using particle methods to estimate the nonlinear changepoint sequence, and Kalman filtering/smoothing to estimate the linear state components. For the deterministic case, smoothing is achieved by sampling an augmented target distribution using MCMC. Simulations demonstrate that the smoothers generate approximation with improved particle diversity and accuracy when compared to the filters.



%\appendices
%\section{Initialisation of Backwards Kalman Filter} \label{app:init_backwards_KF}
%
%The backwards Kalman filter recursion may be initialised exactly by inversion of the observation model. By stacking up the last $L+1$ observations into a single vector, it is possible to write down a joint Gaussian distribution conditional on the $(N-L)$th state. This may be inverted to produce an improper Gaussian density for $x_{N-L}$,
%%
%\begin{IEEEeqnarray}{rCl}
% \IEEEeqnarraymulticol{3}{l}{p(y_{N-L:N}|x_{N-L}) = \mathcal{N}( \mathbf{y}_{N-L:N} | H_{N-L} x_{N-L}, \Gamma_{N-L} ) } \\
% & \propto & \mathcal{N}(x_{N-L} | (H_{N-L}^T \Gamma_{N-L} H_{N-L})^{-1} H_{N-L}^T \Gamma_{N-L}, (H_{N-L}^T \Gamma_{N-L} H_{N-L})^{-1} )      ,
%\end{IEEEeqnarray}
%
%where $H_{N-L}$ and $\Gamma_{N-L}$ may be constructed from the system models and,
%%
%\begin{IEEEeqnarray}{rCl}
%\mathbf{y}_{N-L:N} & = & \begin{bmatrix}y_N \\ y_{N-1} \\ \vdots \\ y_{N-L} \end{bmatrix}     .
%\end{IEEEeqnarray}
%
%This should effected for the smallest value of $L$ such that the matrix inversions possible.


%\newpage
\bibliographystyle{IEEEtran}
\bibliography{D:/pb404/Dropbox/PhD/Cleanbib}
\input{D:/pb404/Dropbox/PhD/Biographies/IEEE-Bunch.tex}
\input{D:/pb404/Dropbox/PhD/Biographies/IEEE-Godsill.tex}
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


























