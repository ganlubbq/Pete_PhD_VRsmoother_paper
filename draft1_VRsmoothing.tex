\documentclass[journal]{IEEEtran}


\usepackage{cite}
\usepackage[pdftex]{graphicx}
\usepackage[cmex10]{amsmath}
\usepackage{amsfonts}
\usepackage{algorithmic}
\usepackage{array}
\usepackage{mdwmath}
\usepackage{mdwtab}
%\usepackage{eqparbox}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{fixltx2e}
\usepackage{url}
\usepackage{color}

\newenvironment{meta}[0]{\color{red} \em}{}

% correct bad hyphenation here
\hyphenation{}

\begin{document}

\title{Smoothing Algorithms for Variable Rate Models}

\author{Pete~Bunch,~\IEEEmembership{}
        Simon~Godsill,~\IEEEmembership{Member,~IEEE,}% <-this % stops a space
\thanks{P. Bunch and S. Godsill are with the Department
of Engineering, Cambridge University, UK. email: \{pb404,sjg30\}@cam.ac.uk}% <-this % stops a space
\thanks{Manuscript received January 01, 1901; revised January 02, 1901.}}

% The paper headers
\markboth{IEEE Transaction in Signal Processing,~Vol.~1, No.~1, January~1901}%
{Bunch \& Godsill: Smoothing Algorithms for Variable Rate Models}

% make the title area
\maketitle

\begin{abstract}
The abstract goes here.
\end{abstract}

\begin{IEEEkeywords}

\end{IEEEkeywords}



\section{Introduction}

\IEEEPARstart{T}{he} objective of sequential Bayesian inference is to estimate an imperfectly observed quantity as it varies over time. This is accomplished through the use of probabilistic models for the state evolution and measurement processes. Often, the latent state is a continuously varying quantity, whereas the observations are made at a discrete set of times. In these circumstances, it is simplest to discretise the state onto the same set of times as the observations. When the system is also Markovian, this leads to the standard ``fixed rate'' hidden Markov model (HMM). The standard HMM is poorly suited to systems where the state evolution contains discontinuities; for example, the price of a financial asset which may display large jumps at random times between periods of diffusion-like behaviour, or the kinematic state of a manoeuvring vehicle which may have sudden changes in the acceleration when turns begin or end. Such problems can be handled more naturally using a ``variable rate'' model, in which the state dynamics are conditioned upon a set of random changepoints which characterise transitions in behaviour.

In a variable rate model, the set of changepoints and associated parameters are modelled as a marked point process (MPP), the mathematical properties of which are thoroughly set out in \cite{Jacobsen2006}. Conditional upon this MPP the state evolves according to some benign dynamics. In \cite{Godsill2007,Whiteley2011}, the conditional state evolution is treated as deterministic, while in \cite{Godsill2007a,Christensen2012} a conditionally linear-Gaussian state model is considered.

The posterior distribution for the changepoint MPP is inherently nonlinear, and cannot be calculated analytically. Instead, inference must be conducted using numerical approximations. The particle filter (introduced by \cite{Gordon1993}) and smoother (see \cite{Doucet2000a,Godsill2004}) are schemes which approximate a posterior distribution using a set of samples, or ``particles'', drawn sequentially from it.  A thorough introduction to particle filtering and smoothing methods can be found in \cite{Cappe2007,Doucet2009}. In \cite{Godsill2007a,Godsill2007,Whiteley2011}, the particle filter was adapted for use with variable rate models, resulting in the variable rate particle filter (VRPF).

The VRPF allows the changepoint sequence -- and hence the current state -- to be estimated sequentially as observations are received. However, estimates can often be improved later once further observations have been made. In this paper, we address the problem of smoothing in variable models, i.e. the estimation of the changepoint sequence and latent state given all the observations. This is achieved with an efficient backward sweep through the observations, in a similar manner to the method for standard HMMs described in \cite{Godsill2004}. Two new schemes are introduced: one for conditionally linear-Gaussian models which exploits the method of Rao-Blackwellisation; and a second for use with conditionally-deterministic models which uses an augmented target distribution in the style of an SMC sampler \cite{DelMoral2006}.

We introduce the general structure of variable rate models in section~\ref{sec:vr_models} and discuss two particular types, those with conditionally linear-Gaussian and conditionally deterministic dynamics. The VRPF is reviewed in section~\ref{sec:vrpf}, and new variable rate smoothing algorithms are described in section~\ref{sec:vrps}. In section~\ref{sec:simuations}, particular examples of variable rate models are presented and their performance demonstrated in a series of simulations.



\section{Variable Rate Models} \label{sec:vr_models}

We consider a general model from time $0$ to $T$, between which observations, $\{y_1 \dots y_N\}$, are made at times $\{t_1 \dots t_N = T\}$. During this period, an unknown number of changepoints, $K$, occur at times $\{\tau_0 = 0, \tau_1 \dots \tau_K \}$, each with associated changepoint parameters, $\{ u_0, u_1 \dots u_K \}$. The pairs $\{\tau_k, u_k\}$ are the elements of an marked point process (MPP). We will refer to the times of the MPP as the ``change-time sequence'' and marks as ``parameter sequence'', and both together as the ``changepoint sequence''. The latent state is a continuous-time process denoted $x(t)$. Discrete sets containing multiple values over time will be written as, e.g. $y_{1:n} = \{y_1 \dots y_n\}$.

The objective for inference will be to estimate the changepoint sequence. This will be denoted as $\theta = \{\tau_{0:K}, u_{0:K}\}$. At a particular time $t_n$, the sequence will be divided into past $\theta_n = \{\tau_{j}, u_{j} \forall j : 0 \leq \tau_j < t_n \}$, and future $\theta_n^+ = \{\tau_{j}, u_{j} \forall j : t_n \leq \tau_j < T \}$. It will also be useful to define a variable for the changepoints which occur in the interval $[t_{n-1},t_n)$, $\theta_{n \setminus n-1} = \{\tau_{j}, u_{j} \forall j : t_{n-1} \leq \tau_j < t_n \}$.

For notational simplicity, the following counting variables are introduced to keep track of the most recent changepoint to have occurred,
%
\begin{IEEEeqnarray}{rCl}
 K(t)  & = & \max(k : \tau_k<t) \\
 K_n   & = & K(t_n)     .
\end{IEEEeqnarray}

The changepoint sequence is assumed to be a Markov process.
%
\begin{IEEEeqnarray}{rCl}
 \{\tau_k, u_k\} & \sim & p(u_k|\tau_k, \tau_{k-1}, u_{k-1}) p(\tau_k|\tau_{k-1}, u_{k-1}) \label{eq:cp_model}
\end{IEEEeqnarray}

The changepoint density will be constructed such that $P(\tau_k < \tau_{k-1}) = 0$.

In the manner of \cite{Whiteley2011}, a survivor function is defined as the probability that no new changepoint occurs before a given time,
%
\begin{IEEEeqnarray}{rCl}
 S(\tau_k, u_k, t) &=& P(\tau_{k+1}>t|\tau_k, u_k) \nonumber \\
              &=& 1 - \int_{\tau_k}^{t} p(\xi|\tau_{k}, u_k) d\xi     .
\end{IEEEeqnarray}

It is now possible to write down a prior for the changepoint sequence, where we use the convention that $\tau_0 = 0$. The existence of such a density for a MPP is addressed in \cite{Jacobsen2006}.

\begin{IEEEeqnarray}{rCl}
p(\theta_n) & = & S(\tau_{K_n},t_n) p(u_0) \prod_{k=1}^{K_n} p(\tau_k, u_k| \tau_{k-1}, u_{k-1}) \label{eq:cp_sequence_prior}
\end{IEEEeqnarray}



\subsection{Conditionally Linear-Gaussian Models}

The first class of variable rate models to be considered is those whose state dynamics are linear-Gaussian conditional on the changepoint sequence. Such a model may be discretised onto the set of observation times in exactly the same manner as a standard the standard HMM.
%
\begin{IEEEeqnarray}{rCl}
 x_n & = & A_n(\theta_{n})x_{n-1} + w_n \\
 y_n & = & C_n(\theta_{n})x_n + v_n       ,
\end{IEEEeqnarray}

where,
%
\begin{IEEEeqnarray}{rCl}
 w_n & \sim & \mathcal{N}(w_n|0, Q_n(\theta_{n})) \\
 v_n & \sim & \mathcal{N}(v_n|0, R_n(\theta_{n}))       .
\end{IEEEeqnarray}

In addition, the prior state distribution should be Gaussian, with known mean and variance.
%
\begin{IEEEeqnarray}{rCl}
 x_0 & \sim & \mathcal{N}(x_0|m_0, P_0)       .
\end{IEEEeqnarray}

If the changepoint sequence is known, or has been estimated, then the state values, $x_n$ may be inferred using optimal Kalman filtering and smoothing recursions. As well as the basic Kalman filter \cite{Kalman1960}, the Rauch-Tung-Striebel (RTS) smoother \cite{Rauch1965} and two-filter smoother \cite{Fraser1969} will prove useful for this step.

Conditionally linear-Gaussian variable rate models were introduced in \cite{Godsill2007a} for a financial inference algorithm. Changepoints correspond to jumps in the value or trend of a security, at which points the process covariance, $Q_n(\theta_n)$, is inflated.



\subsection{Conditionally Deterministic Models}

The second class of variable rate models for consideration is those in which the state is completely specified by the changepoint sequence, with no additional random components. Such a process is commonly referred to as ``piecewise-deterministic'', as the latent state follows a deterministic path between changepoints. In this case, it is not necessary to discretise the state -- it may be kept as a continuous variable.

In general, the state dynamics will be governed by a differential equation which may depend on the entire changepoint sequence. Here we assume that only the most recent changepoint is significant.
%
\begin{IEEEeqnarray}{rCl}
 dx(t) & = & \mathrm{f}(x(t), \tau_{K(t)}, u_{K(t)})     .
\end{IEEEeqnarray}

By introducing a new sequence, $\{ x_0, x_1 \dots x_K \}$, which denotes the value of the state at each changepoint (i.e. $x(\tau_k)$), and assuming that an analytic solution exists, a state transition function may be found,
%
\begin{IEEEeqnarray}{rCll}
 x(t) & = & f(x_{K_n}, v_{K_n}, \tau_{K_n}, t) &, \tau_{K_n} < t <= \tau_{K_{n}+1}    \label{eq:disc_time_state_diff_eq}     .
\end{IEEEeqnarray}

By choosing $t = \tau_{K_{n}+1}$, this equation specifies the state at the next changepoint time. Similarly, by choosing $t=t_n$, the state at the observation times may be calculated. These points will be denoted $\hat{x}_n$. To complete the model, a probabilistic measurement model must be chosen for the observation process, $p(y_n|\hat{x}_n)$.

For convenience, we assume that $x_0$ is known in the following sections. This means that $x(t)$ may be calculated deterministically for all $t$ given $\theta$. However, this condition is easily relaxed by including $x_0$ as a random variable in the posterior distribution.

Target tracking algorithms are commonly based upon fixed rate models (see, e.g. \cite{Li2003} for a thorough survey), in which the target kinematics (position, velocity, etc.) are estimated at a set of fixed times at which observations (e.g. radar measurements) are made. In \cite{Godsill2007a,Godsill2007}, variable rate models were introduced for tracking, in which the state trajectory is divided up by a set of changepoints between which the motion follows a deterministic path governed by motion parameters (accelerations, etc.) which are fixed for that division.



\section{The Variable Rate Particle Filter} \label{sec:vrpf}

The variable rate particle filter (VRPF) is described in \cite{Godsill2007,Godsill2007a}. The objective of the algorithm is to sequentially estimate the posterior distribution of the changepoint sequence, $p(\theta_{n}| y_{1:n})$, at each time $t_n$. This distribution may be expanded using Bayes' rule.
%
\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{p(\theta_{n}|y_{1:n})} \nonumber \\
 & \propto & p(y_n|\theta_{n}, y_{1:n-1}) p(\theta_{n \setminus n-1}|\theta_{n-1}) p(\theta_{n-1}|y_{1:n-1}) \label{eq:vrpf_target}
\end{IEEEeqnarray}

The transition term, $p(\theta_{n \setminus n-1} | \theta_{n-1})$, can be constructed in a similar manner to (\ref{eq:cp_sequence_prior}) \cite{Jacobsen2006}, as a product of density terms for each new changepoint and a survivor function term. In the particular (but common) case that no new changepoints occur within the interval, the density consists of a probability mass on the empty set, with weight $P(\tau_{K_n+1} > t_n | \tau_{K_n+1} > t_{n-1}, \tau_{K_n} )$.
%
\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{p(\theta_{n \setminus n-1} | \theta_{n-1})} \nonumber \\
    & = & \begin{cases} S(\tau_{K_n}, t_n) \prod\limits_{j:t_{n-1} \leq \tau_j < t_n} p(\tau_j, u_j| \tau_{j-1}, u_{j-1}, \tau_j>t_{n-1}) & K_n > K_{n-1} \\
                        S(\tau_{K_n}, t_n) / S(\tau_{K_n}, t_{n-1}) & K_n = K_{n-1} \end{cases} \IEEEeqnarraynumspace \label{eq:cp_sequence_trandens}
\end{IEEEeqnarray}

For all but the first changepoint in the interval, the density is given by the prior model of (\ref{eq:cp_model}). For the first changepoint, indexed by $k=K_{n-1}+1$, we must account for the fact that a changepoint cannot occur before $t_{n-1}$,
%
\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{p(\tau_{k}, u_{k}| \tau_{k-1}, u_{k-1}, \tau_{k}>t_{n-1})} \nonumber \\
  & = & \frac{1}{S(\tau_{k-1}, t_{n-1})} \begin{cases} p(\tau_{k}, u_{k}| \tau_{k-1}, u_{k-1}) & \tau_{k} > t_{n-1} \\ 0 & \tau_{k} < t_{n-1} \end{cases}  \IEEEeqnarraynumspace \label{eq:cp_cond_model}   .
\end{IEEEeqnarray}

Practically, because changepoints will be relatively rare events, it is not likely that more than one new changepoint will occur between $t_{n-1}$ and $t_n$.

The target distribution of (\ref{eq:vrpf_target}) cannot be calculated analytically, but may be approximated numerically. A particle filter is an algorithm for approximating a probability distribution using a set of weighted samples (or ``particles'') drawn from that distribution. In this case, each particle will be a set of changepoint times and parameters.
%
\begin{equation}
 \hat{p}(\theta_{n}|y_{1:n}) = \sum_j w_n^{(j)} \delta_{\theta_{n}^{(j)}}(\theta_{n})
\end{equation}

where $\delta_x(X)$ is a dirac probability mass at $X=x$.

The particle filter works recursively. At the $n$th step, a particle, $\theta_{n-1}^{(i)}$, is first resampled from those approximating the filtering distribution at the $(n-1)$th step, using an appropriately chosen set of proposal weights.
%
\begin{equation}
 q(\theta_{n-1}) = \sum_j v_{n-1}^{(j)} \delta_{\theta_{n-1}^{(j)}}(\theta_{n-1})
\end{equation}

The choice of weights determines the type of resampling used. The simplest choice, $v_{n-1}^{(j)} = 1/N_F$ (where $N_F$ is the number of filter particles) may be achieved by simply omitting this step all together and using the particles of $\hat{p}(\theta_{n-1}|y_{1:n-1})$. This, however, leads to degeneracy of the particle weights over time. Conventional resampling is achieved by using $v_{n-1}^{(j)} = w_{n-1}^{(j)}$. Any other choice results in an auxiliary particle filter \cite{Pitt1999}. For further discussion of resampling, see \cite{Cappe2007,Doucet2009,Douc2005}.

Next, an extension to the changepoint sequence, $\theta_{n \setminus n-1}^{(i)}$, is proposed from an importance distribution, $q(\theta_{n \setminus n-1}|\theta_{n-1}^{(i)}, y_n)$, and concatenated to $\theta_{n-1}$ to create an estimate of $\theta_n$. Finally, the particle is weighted according to the ratio of the target and proposal densities.
%
\begin{IEEEeqnarray}{rCl}
w_n^{(i)} & = & \frac{ p(\theta_{n}^{(i)}|y_{1:n}) }{ q(\theta_{n}) } \nonumber \\
    & \propto & \frac{ p(y_n|\theta_n, y_{1:n-1}) p(\theta_{n \setminus n-1}|\theta_{n-1}) p(\theta_{n-1}|y_{1:n-1}) }{ q(\theta_{n-1}) q(\theta_{n \setminus n-1}|\theta_{n-1}^{(i)}, y_n) } \nonumber \\
    & =       & \frac{w_{n-1}^{(i)}}{v_{n-1}^{(i)}} \times \frac{ p(y_n|\theta_n, y_{1:n-1}) p(\theta_{n \setminus n-1}|\theta_{n-1}) }{ q(\theta_{n \setminus n-1}|\theta_{n-1}^{(i)}, y_n) } \label{eq:vrpf_weights}
\end{IEEEeqnarray}

The normalisation may be enforced by scaling the weights so that they sum to $1$.

For the most basic ``bootstrap'' \cite{Gordon1993} form of the VRPF, $\theta_{n \setminus n-1}$ may be proposed from the prior transition density (\ref{eq:cp_sequence_trandens}). This can be achieved by sampling new changepoints sequentially from the transition model (\ref{eq:cp_model}) (apart from the first which is sampled from (\ref{eq:cp_cond_model})) until one falls after the current time, $t_n$. This final future changepoint is discarded. (This process can be thought of as sampling the entire future changepoint sequence from $t_{n-1}$ onwards, and then marginalising those which fall after $t_n$.) The bootstrap proposal leads to the usual simplification of the weight formula.
%
\begin{IEEEeqnarray}{rCl}
w_n^{(i)} & = & \frac{w_{n-1}^{(i)}}{v_{n-1}^{(i)}} \times p(y_n|\hat{x}_n) \label{eq:bootstrap_vrpf_weights}
\end{IEEEeqnarray}

The choice of proposal weights, $\{v_{n-1}^{(i)}\}$, requires particular attention in the design of VRPFs. In some models a changepoint may not have an immediate effect on the observations, especially if a jump occurs in some quantity which is only observed via its integral, e.g. if there is a jump in the acceleration of a moving object, yet only the position is measured, the change will not be apparent until several more observations have been made. In the meantime, particles which contain a changepoint at the correct time may all have been removed by the resampling process. To avoid this loss of good particles, proposal weights should be chosen which preserve a significant number of low-weight particles. One scheme which has been found to work well is described in \cite{Godsill2007}, in which proposal weights are given by:
%
\begin{IEEEeqnarray}{rCl}
v_{n-1}^{(i)} & \propto & \max ( 1, N_F w_{n-1}^{(i)} )
\end{IEEEeqnarray}

It only remains to consider the likelihood term required for evaluation of the importance weights, $p(y_n|\theta_n, y_{1:n-1})$. The form of this term depends on the particular model under consideration. In the following sections, the likelihood expressions for the conditionally linear-Gaussian and deterministic cases are considered.



\subsection{Conditionally Linear-Gaussian Likelihoods} \label{sec:rb-vrpf}

For a conditionally linear-Gaussian model, the required likelihood term, $p(y_n|\theta_n, y_{1:n-1})$ is the predictive distribution estimated by the Kalman filter. Conveniently, the Kalman filter also provides us with an estimate of the current state given the changepoint sequence and all the preceding observations. It follows from the the Gaussian dynamics and prior that these distributions are all Gaussian as well, \cite{Anderson1979},
%
\begin{IEEEeqnarray}{rCl}
 p(x_n|\theta_{n}, y_{1:n-1}) & = & \mathcal{N}(x_n|m_n^-, P_n^-) \\
 p(x_n|\theta_{n}, y_{1:n}) & = & \mathcal{N}(x_n|m_n, P_n) \\
 p(y_n|\theta_{n}, y_{1:n-1}) & = & \mathcal{N}(y_n|\mu_n, S_n)     ,
\end{IEEEeqnarray}

with means and variances given by the following standard recursions (dependence on $\theta_{n}$ suppressed for clarity),
%
\begin{IEEEeqnarray}{rCl}
 m_n^- & = & A_n m_{n-1} \label{eq:kf_predict_start} \\
 P_n^- & = & A_n P_{n-1} A_n^T + Q_n \\
 \mu_n & = & C_n m_n^- \\
 S_n   & = & C_n P_n^- C_n^T + R_n \label{eq:kf_predict_stop} \\
 K_n   & = & P_n^- C_n^T S_n^{-1} \label{eq:kf_update_start}\\
 m_n   & = & m_n^- + K_n (y_n - \mu_n) \\
 P_n   & = & P_n^- - K_n S_n K_n^T \label{eq:kf_update_stop}    .
\end{IEEEeqnarray}

This completes the requirements for the particle filter, resulting in the final algorithm shown in Fig.~\ref{alg:RBVRPF}. The concept of estimating the posterior for just the changepoint sequence with a particle filter rather than the joint posterior over changepoints and linear states is an example of Rao-Blackwellisation (see, e.g. \cite{Casella1996,Doucet2000}), so this algorithm is known as the Rao-Blackwellised variable rate particle filter (RB-VRPF) \cite{Godsill2007a,Christensen2012}.

\begin{figure}
\fbox{\parbox{\columnwidth}{
\begin{algorithmic}[1]
\STATE For each $i$, initialise particle changepoint sequence with $\{\theta_{0}^{(i)}\} \gets \{\tau_0^{(i)}, u_0^{(i)}$, where $\tau_0^{(i)}=0$ and $\{u_0^{(i)}\} \sim p(u_0)$.
\STATE For each $i$, initialise particle sufficient statistics, $m_0^{(i)}$ and $P_0^{(i)}$ with prior values.
\FOR{$n=1 \dots N$}
  \FOR{$i=1 \dots N_F$}
  	\STATE Sample a changepoint history $\theta_{n-1}^{(i)} \sim \sum_j v_{n-1}^{(j)} \delta_{\theta_{n-1}^{(j)}}(\theta_{n-1})$.
    \STATE Propose a sequence extension $\theta_{n \setminus n-1}^{(i)} \sim q(\theta_{n \setminus n-1} | \theta_{n-1}^{(i)})$.
    \STATE Add extension to changepoint sequence $\theta_n^{(i)} \gets \theta_{n-1}^{(i)} \cup \theta_{n \setminus n-1}^{(i)}$.
    \STATE Predict state mean and covariance $\mu_n^{(i)}$ and $S_n^{(i)}$ using (\ref{eq:kf_predict_start})~to~(\ref{eq:kf_predict_stop}).
    \STATE Calculate weight $w_n^{(i)}$ using (\ref{eq:vrpf_weights}).
    \STATE Update state mean and covariance $m_n^{(i)}$ and $P_n^{(i)}$ using (\ref{eq:kf_update_start})~to~(\ref{eq:kf_update_stop}).
  \ENDFOR
  \STATE Scale weights such that $\sum_i w_n^{(i)}=1$.
\ENDFOR
\end{algorithmic}
}}
\label{alg:RBVRPF}
\caption{Rao-Blackwellised variable rate particle filter}
\end{figure}



\subsection{Conditionally Deterministic Likelihoods} \label{sec:pd-vrpf}

When a conditionally deterministic model is used, the state at observation time $t_n$ is specified by the changepoint sequence $\theta_n$ (plus the initial state, $x_0$), using (\ref{eq:disc_time_state_diff_eq}). Thus, the required likelihood term is simply given by,
%
\begin{IEEEeqnarray}{rCl}
 p(y_n|\theta_{n}, y_{1:n-1}) & = & p(y_n|\hat{x}_n)     .
\end{IEEEeqnarray}

This leads to a particle filter for variable rate models with conditionally deterministic dynamics, summarised in Fig.~\ref{alg:VRPF}. The resulting trajectories $x(t)^{(i)}$ for each particle are realisations from a piecewise-deterministic process, so this algorithm is named the piecewise-deterministic variable rate particle filter (PD-VRPF).

\begin{figure}
\fbox{\parbox{\columnwidth}{
\begin{algorithmic}[1]
\STATE For each $i$, initialise particle changepoint sequence with $\{\theta_{0}^{(i)}\} \gets \{\tau_0^{(i)}, u_0^{(i)}$, where $\tau_0^{(i)}=0$ and $\{u_0^{(i)}\} \sim p(u_0)$.
\FOR{$n=1 \dots N$}
  \FOR{$i=1 \dots N_F$}
  	\STATE Sample a history $\theta_{n-1}^{(i)} \sim \sum_j v_{n-1}^{(j)} \delta_{\theta_{n-1}^{(j)}}(\theta_{n-1})$.
    \STATE Propose a sequence extension $\theta_{n \setminus n-1}^{(i)} \sim q(\theta_{n \setminus n-1}|\theta_{n-1}^{(i)}, y_{n})$.
    \STATE Add extension to changepoint sequence $\theta_n^{(i)} \gets \theta_{n-1}^{(i)} \cup \theta_{n \setminus n-1}^{(i)}$.
    \STATE Calculate state $\hat{x}_n$ using (\ref{eq:disc_time_state_diff_eq}).
    \STATE Calculate particle weight using (\ref{eq:vrpf_weights}).
  \ENDFOR
  \STATE Scale weights such that $\sum_i w_n^{(i)}=1$.
\ENDFOR
\end{algorithmic}
}}
\label{alg:VRPF}
\caption{Piecewise deterministic variable rate particle filter}
\end{figure}



\subsection{Improving the Variable Rate Particle Filter}

The bootstrap versions of the VRPFs described in sections~\ref{sec:rb-vrpf} and~\ref{sec:pd-vrpf} may perform poorly if changepoints are not obvious until significantly after they occur. For example, in a tracking example, if a jump occurs in the acceleration, but only the position is observed, then this change may not be obvious until a number of observations have arrived. In this case, the estimation may be improved by the introduction of resample-move (RM) steps \cite{Gilks2001}. In an RM scheme, optional Metropolis-Hastings (MH) moves are conducted to alter the particle states after the importance sampling has taken place. For variable rate models, any one of the previous changepoints, $\tau_k$, or associated parameters, $u_k$, could be adjusted. Because more observations are available than when the changepoint was first proposed, it may be possible to construct more informed proposals and so move the changepoints towards regions with higher posterior probability. It is even possible to retrospectively add or remove changepoints, using reversible jump MH moves \cite{Green1995}. Variable rate particle filters using RM with piecewise deterministic models are described in \cite{Whiteley2011,Gilholm2008}.

Rather than conducting the IS and MH steps separately, it is possible to combine them using the framework of SMC samplers \cite{DelMoral2006}. This was suggested in \cite{Whiteley2011}, again for piecewise deterministic dynamics, but the extension to conditionally linear-Gaussian models is straightforward.

Filtering schemes which alter past changepoints -- whether using an SMC sampler or RM -- are computationally expensive, because many likelihood calculations must be conducted, for each observation from the time of the change onwards. In some cases, it may be simpler to just use a bootstrap filter with more particles.



\section{Variable Rate Particle Smoothing} \label{sec:vrps}

A filter conducts inference sequentially as new observations are introduced. The purpose of a smoother is to produce a second estimate once all the observations have been made, using future values to improve upon the filter performance. Estimating changepoints online is a challenging task because the presence of a change may not be obvious until after it has happened. Thus, it is anticipated that a smoothing algorithm will provide significantly improved performance at changepoint estimation.

The target distribution for a variable rate smoothing algorithm is the posterior distribution over the entire changepoint sequence, $p(\theta|y_{1:N})$. A particle approximation to this distribution is generated by the final step of the VRPF. However, in the same manner as the fixed rate filter-smoother of \cite{Kitagawa1996}, this approximation is likely to lack path-space diversity -- because of the necessary resampling step in the filtering algorithm, the particles all share the same set of changepoints before a particular time, with variation only appearing for changepoints closer to $T$. For a good characterisation of the smoothing distribution, it is necessary to rejuvenate the set of particles. This is achieved with a backward pass through the observations in a similar manner to the forward-backward method described in \cite{Godsill2004}.

The target distribution may be factorised as follows,
%
\begin{IEEEeqnarray}{rCl}
 p(\theta|y_{1:N}) = p(\theta_{n}^{+}|y_{1:N}) p(\theta_{n}|\theta_{n}^{+}, y_{1:N})     .
\end{IEEEeqnarray}

This suggests a sequential strategy for smoothing. A particle drawn from $p(\theta_{n}^{+}|y_{1:N})$ may be extended backwards by sampling from the backwards conditional distribution, $p(\theta_{n}|\theta_{n}^{+}, y_{1:N})$ and concatenating the two partial sequences. The new particle will be a sample from the target distribution, but the resulting approximation will still suffer from low path-space diversity before time $t_{n-1}$. Therefore, $\theta_{n-1}$ is marginalised by simply discarding the changepoints which occur before this time. This results in a particle drawn from $p(\theta_{n-1}^{+}|y_{1:N})$. The procedure then continues recursively. After a complete backwards pass through the observations, a single particle from the target distribution will have been generated. The process is then repeated until sufficient samples are obtained.

At step $n$ for a given particle, the future changepoint sequence may be considered to be fixed. It remains to devise a method for drawing samples from the backwards conditional distribution, $p(\theta_{n}|\theta_{n}^{+}, y_{1:N})$. Such methods are discussed in the following sections for the two classes of models.



\subsection{Conditionally Linear-Gaussian Smoothing} \label{sec:rb-vrps}

When the state dynamics are linear-Gaussian conditional on the changepoint sequence, it is possible split the dependence on the observations into past and future by introducing the current state as an additional variable. This trick was used in \cite{Sarkka2012} in the derivation of the Rao-Blackwellised particle filter for fixed rate conditionally linear-Gaussian models.
%
\begin{IEEEeqnarray}{rCl}
 \IEEEeqnarraymulticol{3}{l}{p(\theta_{n}|\theta_{n}^+, y_{1:N})} \nonumber \\
\qquad & \propto & p(\theta_{n}, \theta_{n}^+| y_{1:N}) \nonumber  \\
       & =       & \int p(x_n, \theta_{n}, \theta_{n}^+| y_{1:N}) dx_n \nonumber  \\
       & \propto & \int p(y_{n+1:N}|x_n, \theta_{n}, \theta_{n}^+, y_{1:n}) p(x_n, \theta_{n}, \theta_{n}^+| y_{1:n}) dx_n \nonumber \\
       & = & \int p(y_{n+1:N}|x_n, \theta_{n}^+) p(x_n|\theta_{n}, y_{1:n}) dx_n \nonumber \\
       &   & \times p(\theta_{n}^+|\theta_{n}) p(\theta_{n}|y_{1:n})
\end{IEEEeqnarray}

Finally, the particle approximation is substituted for the filtering distribution.
%
\begin{IEEEeqnarray}{rCl}
\hat{p}(\theta_{n}|\theta_{n}^+, y_{1:N}) & = & \sum_i \tilde{w}_{n}^{(i)} \delta_{\theta_{n}^{(i)}}(\theta_{n})  \label{eq:rb-vrps_back_cond}
\end{IEEEeqnarray}

where the backwards conditional weights are given by
%
\begin{IEEEeqnarray}{rCl}
 \tilde{w}_n & \propto & \int p(y_{n+1:N}|x_n, \theta_{n}^+) \nonumber \\
             &         & \times p(x_n|\theta_{n}^{(i)}, y_{1:n}) dx_n p(\theta_{n}^+|\theta_{n}^{(i)}) \label{eq:rb-vrps_back_cond_weight}
\end{IEEEeqnarray}

As before, normalisation is enforced by scaling the weights so that they sum to $1$.

The changepoint transition density may be expressed as,
%
\begin{IEEEeqnarray}{rCl}
 p(\theta_{n}^+|\theta_{n}) &=      & p(\tau_{K_n+1:K}, u_{K_n+1:K}|\tau_{K_n}, u_{K_n}, \tau_{K_n+1}>t_n) \nonumber \\
                                    &\propto& p(u_{K_n+1}|\tau_{K_n+1}, \tau_{K_n}, u_{K_n}) p(\tau_{K_n+1}|\tau_{K_n}, u_{K_n})     .
\end{IEEEeqnarray}

The integral in~(\ref{eq:rb-vrps_back_cond_weight}) contains two terms involving the current state, $x_n$. The first is the familiar state posterior generated by the Kalman filter using (\ref{eq:kf_predict_start}--\ref{eq:kf_update_stop}).
%
\begin{IEEEeqnarray}{rCl}
p(x_n|\theta_{n}^{(i)}, y_{1:n}) & = & \mathcal{N}(x_n|m_n^{(i)}, P_n^{(i)})
\end{IEEEeqnarray}

The mean and covariance of this distribution will have been calculated during the filtering stage, and can be stored for use now in the smoother.

The second state term in (\ref{eq:rb-vrps_back_cond_weight}) is the likelihood, $p(y_{n+1:N}|x_n, \tilde{\theta}_{n}^+)$. This may be considered to be an improper density over $x_n$, and may be calculated analytically using a backwards Kalman filter, in a similar manner to that used in the two-filter smoother \cite{Fraser1969,Anderson1979,Sarkka2012}. Such a backwards Kalman filter uses the following recursions. Details are provided in appendix~\ref{app:backward_filter}, and in the aforesaid references.
%
\begin{IEEEeqnarray}{rCl}
 p(y_{n+1:N}|x_n, \theta_{n}^+) & \propto & \mathcal{N}(x_n|\tilde{m}_n^-, \tilde{P}_n^-) \\
 p(y_{n:N}|x_n, \theta_{n}^+) & \propto & \mathcal{N}(x_n|\tilde{m}_n, \tilde{P}_n)
\end{IEEEeqnarray}

\begin{IEEEeqnarray}{rCl}
 \tilde{m}_n^- & = & A_{n+1}^{-1} \tilde{m}_{n+1} \label{eq:backward_kf_predict_start} \\
 \tilde{P}_n^- & = & A_{n+1}^{-1} (\tilde{P}_{n+1} + Q_{n+1}) A_{n+1}^{-T} \label{eq:backward_kf_predict_stop} \\
 \tilde{\mu}_n & = & C_n \tilde{m}_n^- \label{eq:backward_kf_update_start} \\
 \tilde{S}_n   & = & C_n \tilde{P}_n^- C_n^T + R_n \\
 \tilde{K}_n   & = & \tilde{P}_n^- C_n^T \tilde{S}_n^{-1} \\
 \tilde{m}_n   & = & \tilde{m}_n^- + \tilde{K}_n (y_n - \tilde{\mu}_n) \\
 \tilde{P}_n   & = & \tilde{P}_n^- - \tilde{K}_n \tilde{S}_n \tilde{K}_n^T \label{eq:backward_kf_update_stop}
\end{IEEEeqnarray}

Exact methods for initialising this recursion are discussed in appendix~\ref{app:backward_filter}. However, it is often sufficient to use an approximation, for example $\tilde{m}_N^{(i)} = m_N^{(i)}$ and $\tilde{P}_N^{(i)} = P_N^{(i)}$.

Substituting into (\ref{eq:rb-vrps_back_cond_weight}), the backwards conditional weights are given by,
%
\begin{equation}
 \tilde{w}_n \propto p(\theta_{n}^+|\theta_{n}^{(i)}) \mathcal{N}(\tilde{m}_n^-|m_n, \tilde{P}_n^- + P_n)     .
\label{eq:rb-vrps_back_cond_weight2}
\end{equation}

Using these weights, a sample of $\theta_{n}$ may be drawn from the particle distribution of (\ref{eq:rb-vrps_back_cond}), completing the smoothing algorithm. Once sampling has progressed backwards from $n=N \dots 1$, a particle from the smoothing distribution will have been generated. This procedure may then be repeated until sufficient particles have been obtained. The algorithm is summarised in Fig.~\ref{alg:RBVRPS}.

\begin{figure}
\fbox{\parbox{\columnwidth}{
\begin{algorithmic}[1]
  \STATE Run Rao-Blackwellised variable rate particle filter to approximate $p(\theta_{n}|y_{1:n})$ with weighted particles $\{\theta_{n}^{(i)}, w_{n}^{(i)}\}$ and $\{p(x_n|\theta_{n}^{(i)},y_{1:n})\}$ as normal distributions with moments $\{m_{n}^{(i)}\}$ and $\{P_{n}^{(i)}\}$. Store all results.
  \FOR{$i=1 \dots N_S$}
  	\STATE Initialise particle using $\theta^{(i)} \sim \sum_j w_N^{(j)} \delta_{\theta^{(j)}}(\theta)$.
    \STATE Initialise sufficient statistics $\tilde{m}_N^{(i)}$ and $\tilde{P}_N^{(i)}$ (see text).
    \FOR{$n=N \dots 1$}
      \STATE Predict state mean and covariance $\tilde{m}_n^{-(i)}$ and $\tilde{P}_n^{-(i)}$ using \ref{eq:backward_kf_predict_start} to \ref{eq:backward_kf_predict_stop}.
      \FOR{$j=1 \dots N_P$}
	      \STATE Calculate weight $\tilde{w}_n^{(j)}$ using (\ref{eq:rb-vrps_back_cond_weight2}).
      \ENDFOR
      \STATE Sample $\theta_{n}^{(i)} \sim \sum_j \tilde{w}_n^{(j)} \delta_{\theta_{n}^{(j)}}(\theta_{n})$.
      \STATE Update state mean and covariance $\tilde{m}_n^{(i)}$ and $\tilde{P}_n^{(i)}$ using \ref{eq:backward_kf_update_start} to \ref{eq:backward_kf_update_stop}.
      \STATE Discard $\theta_{n-1}^{(i)}$.
    \ENDFOR
  \ENDFOR
\end{algorithmic}
}}
\caption{Rao-Blackwellised Variable Rate Particle Smoother}
\label{alg:RBVRPS}
\end{figure}

The algorithmic complexity of this variable rate particle smoother for conditionally linear-Gaussian models is $O(N_F \times N_S \times N)$. It is possible to reduce this by using an MCMC sampling scheme in the style of \cite{Bunch2012}, in which case it is no longer necessary to calculate the backwards sampling weights for every filter particle.



\subsection{Conditionally Deterministic Smoothing} \label{sec:pd-vrps}

In a piecewise-deterministic system, the trick of introducing a state variable to split the set of observations into past and future does not work. Furthermore, the simplifications used by the fixed rate particle smoother which exploit the Markovian nature of the state sequence \cite{Godsill2004} are of no help, because past changepoints are not independent of future observations (i.e. $p(\theta_{n}|\theta_{n}^{+}, y_{1:N}) \ne p(\theta_{n}|\theta_{n}^{+}, y_{1:n}))$. A new approach is required.

Consider the augmented MPP consisting of $\tilde{\theta} = \{\tau_{0:K}, u_{0:K}, x_{0:K}\}$ ($\tilde{\theta}_n$ and $\tilde{\theta}_n^+$ defined in the same manner as before). The mark corresponding to $\tau_k$ is now the parameter-state pair $(u_k, x_k)$, i.e. the state at the time of the change plus the parameters for the next division. The smoother is formulated by factorising the augmented sequence posterior distribution as before,
%
\begin{IEEEeqnarray}{rCl}
 p(\tilde{\theta}|y_{1:N}) = p(\tilde{\theta_{n}}^{+}|y_{1:N}) p(\tilde{\theta}_{n}|\tilde{\theta}_{n}^{+}, y_{1:N})     .
\end{IEEEeqnarray}

The backwards conditional term may be expanded as,
%
\begin{IEEEeqnarray}{rCl}
p(\tilde{\theta}_{n}|\tilde{\theta}_{n}^{+}, y_{1:N}) & \propto & p(y_{1:N}|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}) p(\tilde{\theta}_{n}^{+}|\tilde{\theta}_{n}) p(\tilde{\theta}_{n})    .
\end{IEEEeqnarray}

For each particle in the filtering approximations, the changepoint state values $x_{0:K_n}$ may be calculated deterministically from $\theta_n$ and stored during the filtering procedure. The obvious strategy then is to recursively sample $\tilde{\theta}_{n}$ from the backwards conditional term, using the re-weighted particles of the $n$th filtering approximation. However, the conditionally deterministic structure prevents this from working. $x(t)$ is fully determined by $\tilde{\theta}_{n}$ up to $\tau_{K_n+1}$, but this will not usually match up with $x_{K_n+1}$ as specified in $\tilde{\theta}_{n}^+$. The result is that $p(\tilde{\theta}_{n}^{+}|\tilde{\theta}_{n})=0$ for (almost) all particles. In other words, we are trying to join two deterministic state trajectories together, but they do not meet up in the middle.

The solution to this problem is provided by an idea from the Sequential Monte Carlo (SMC) samplers of \cite{DelMoral2006}. Rather than just using a value of $\tilde{\theta}_{n}$ from the filtering particles, a replacement, $u_{K_n}'$, is proposed for the existing parameter corresponding to the final changepoint, $u_{K_n}$, with a value chosen such that the past and future paths meet up. The modified sequence is denoted $\tilde{\theta}_{n}'$. This requires a new condition to be imposed on the state dynamics. For any pair of adjacent changepoints, $(\tau_k,x_k)$, and $(\tau_{k+1},x_{k+1})$ it must be possible to calculate a parameter value which results in the transition from the former to the latter. As a rule of thumb, this requires the number of dimensions of $u_k$ to be greater or equal to the number of dimensions of $x_k$.

The target distribution is augmented by introduction of an artificial density to cover the new changepoint sequence and the discarded parameter. It is clear that this new target distribution,

\begin{IEEEeqnarray}{rCl}
 p(\tilde{\theta}_{n}'|\tilde{\theta}_{n}^{+}, y_{1:N}) L(u_{K_n}|\tilde{\theta}_{n}', \tilde{\theta}_{n}^{+}, y_{1:N}) \label{eq:pd-vrps_target}     ,
\end{IEEEeqnarray}

admits the desired posterior term as a marginal.

The augmented target distribution may be sampled using Markov chain Monte Carlo (MCMC) \cite{Gilks1996}, in a similar manner to the fixed rate smoother of \cite{Bunch2012}. Metropolis-Hastings (MH) steps are conducted to draw samples, $\{\tilde{\theta}_{n}, u_{K_n}'\}$, from the target distribution by sampling a proposal and accepting the new values with a given probability. The proposal is conducted by first resampling a particle from the $n$th filtering approximation and then sampling the replacement parameter from an appropriate proposal density. Thus a sample is drawn from,

\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{p(\tilde{\theta}_{n}|y_{1:n}) q(u_{K_n}|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N})} \nonumber \\
 \qquad & \propto & p(y_{1:n}|\tilde{\theta}_{n}) p(\tilde{\theta}_{n}) q(u_{K_n}'|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N}) \label{eq:pd-vrps_proposal}     .
\end{IEEEeqnarray}

Hence the ratio, of target (\ref{eq:pd-vrps_target}) and proposal (\ref{eq:pd-vrps_proposal}) densities is,

\begin{IEEEeqnarray}{rCl}
\beta_n &\propto& \frac{ p(y_{r_n^-:r_n^+}|\tilde{\theta}_{n}') }{ p(y_{r_n^-:n}|\tilde{\theta}_{n}) } \nonumber \\
  & & \times \frac{ p(\tilde{\theta}_{n}^{+}|\tilde{\theta}_{n}') p(u_{K_n}'|\tilde{\theta}_n \setminus u_{K_n}) }{ p(u_{K_n}|\tilde{\theta}_n \setminus u_{K_n}) } \nonumber \\
  & & \times \frac{ L(u_{K_n}|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N}) }{ q(u_{K_n}'|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N}) } \label{eq:pd-vrps_tpr}    ,
\end{IEEEeqnarray}

where $r_n^- = \min( m : t_m > \tau_{K_n} )$ and $r_n^+ = \max( m : t_m < \tau_{K_n+1} )$.

The transition density term will include a delta function with unit probability mass at the point for which the past and future state trajectories match up.

\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{p(\tilde{\theta}_{n}^{+}|\tilde{\theta}_{n}') \propto p(u_{K_n+1}|\tau_{K_n+1}, \tau_{K_n}, u_{K_n})} \nonumber \\ \times p(\tau_{K_n+1}|\tau_{K_n}, u_{K_n}) \delta_{f(x_{K_n}, v_{K_n}, \tau_{K_n}, \tau_{K_n+1})}(x_{K_n+1})
\end{IEEEeqnarray}

If there is only one value of $u_{K_n}'$ for which the two trajectories match up, then the proposal density $q(u_{K_n}'|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N})$ is also a delta function, with unit probability mass at the one valid value. The remaining terms are likelihoods and parameter transition density terms, defined by the system equations. The simplest choice for $L(.|.)$ is simply as a uniform distribution so that it cancels out in the acceptance probability.

If $\beta_n^{(m-1)}$ is the target-proposal ratio for the current state in the chain, and $\beta_n^*$ that for the proposed state, then the acceptance probability is given by,

\begin{IEEEeqnarray}{rCl}
\alpha_n^{(m)} = \min \left( 1, \frac{\beta_n^*}{\beta_n^{(m-1)}} \right) \label{eq:pd-vrps_ap}     .
\end{IEEEeqnarray}

The algorithm is summarised in Fig.~\ref{alg:VRPS}.

\begin{figure}
\fbox{\parbox{\columnwidth}{
\begin{algorithmic}[1]
  \STATE Run variable rate particle filter to approximate $p(\tilde{\theta}_{n}|y_{1:n})$ with weighted particles $\{\tilde{\theta}_{n}^{(i)}, w_{n}^{(i)}\}$. Store all results.
  \FOR{$i=1 \dots N_S$}
  	\STATE Initialise particle from $N$th filter approximation $\tilde{\theta}^{(i)} \sim \sum_j w_N^{(j)} \delta_{\tilde{\theta}^{(j)}}(\tilde{\theta})$.
    \FOR{$n=N \dots 1$}
      \STATE Get the current changepoint history $\tilde{\theta}_n^{(i)(0)} \gets \tilde{\theta}_n^{(i)}$.
      \FOR{$m=1 \dots M$}
        \STATE Propose a new changepoint history from $n$th filter approximation $\tilde{\theta}_n^{(i)*} \sim \sum_j w_n^{(j)} \delta_{\tilde{\theta}_{n}^{(j)}}(\tilde{\theta}_{n})$.
        \STATE Propose a replacement parameter $u_{K_n}'^* \sim q(u_{K_n}|\tilde{\theta}_{n}, \tilde{\theta}_{n}^{+}, y_{1:N})$.
        \STATE Construct a new changepoint history, $\tilde{\theta}_n'^{(i)*}$, by replacing $u_{K_n}^*$ with $u_{K_n}'^*$.
        \STATE Calculate acceptance probability $\alpha_n^{(m)}$ using (\ref{eq:pd-vrps_tpr}) and (\ref{eq:pd-vrps_ap}).
        \STATE With probability $\alpha_n^{(m)}$, $\tilde{\theta}_n^{(i)(m)} \gets \tilde{\theta}_n^{(i)*}$. Otherwise, $\tilde{\theta}_n^{(i)(m)} \gets \tilde{\theta}_n^{(i)(m-1)}$.
      \ENDFOR
      \STATE Keep final sample $\tilde{\theta}_n^{(i)} \gets \tilde{\theta}_n^{(i)(M)}$.
    \ENDFOR
  \ENDFOR
\end{algorithmic}
}}
\caption{MCMC piecewise-deterministic variable rate particle smoother}
\label{alg:VRPS}
\end{figure}

The Markov chains require no burn-in, because the original value is itself a sample from the target distribution. The number of MH steps, $M$, at each observation time, $n$, allows a trade-off of performance against time. Larger values of $M$ will ensure more unique samples in the smoothing approximation, but will also take longer to execute. In the simulations discussed in this report, $M=1$ was used throughout.






\bibliographystyle{IEEEtran}
\bibliography{D:/pb404/Dropbox/PhD/OTbib}
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




















A Markov chain is initialised by sampling a particle from the approximation generated by the final filtering step. Because this is an approximation of the target distribution, no burn-in is requiired. Proceeding backwards in time, MH steps are conducted by proposing a replacement for the changepoint sequence history from the appropriate filtering approximation. At the $n$th step, the future changepoints are considered to be fixed, $\tilde{\zeta}_{[t_n,T]}$. A replacement for the past changepoints is proposed from the filtering particles.

\begin{equation}
 \zeta_{[0,t_n]}^* \sim q(\zeta_{[0,t_n]}|y_{1:n}) = \sum_j \gamma_n^{(j)} \delta_{(\zeta_{[0,t_n]}^{(j)})}(\zeta_{[0,t_n]})
\end{equation}

This proposed move is accepted with the following acceptance probability, where $\zeta_{[0,t_n]}^{(m)}$ is the previous sequence of past changepoints in the Markov chain.

\begin{IEEEeqnarray}{rCl}
 \alpha & = & \frac{ p(\zeta_{[0,t_n]}^*, \tilde{\zeta}_{[t_n,T]}|y_{1:N}) q(\zeta_{[0,t_n]}^{(m)}|y_{1:n}) }{ p(\zeta_{[0,t_n]}^{(m)}, \tilde{\zeta}_{[t_n,T]}|y_{1:N}) q(\zeta_{[0,t_n]}^*|y_{1:n}) } \nonumber \\
        & = & \frac{ \gamma_n^{(m)} }{ \gamma_n^* } \times \frac{ p(\tilde{\zeta}_{[t_n,T]}|\zeta_{[0,t_n]}^*) p(\zeta_{[0,t_n]}^*) }{ p(\tilde{\zeta}_{[t_n,T]}|\zeta_{[0,t_n]}^{(m)}) p(\zeta_{[0,t_n]}^{(m)}) } \nonumber \\
        &   &  \times \frac{ p(y_{r_k^-:r_k^+}|\hat{x}_{r_k^-:r_k^+}^*) p(y_{1:r_k^- -1}|\hat{x}_{1:r_k^- -1}^*) }{ p(y_{r_k^-:r_k^+}|\hat{x}_{r_k^-:r_k^+}^{(m)}) p(y_{1:r_k^- -1}|\hat{x}_{1:r_k^- -1}^{(m)}) } \nonumber \\
        & = & \frac{ \gamma_n^{(m)} }{ \gamma_n^* } \times \frac{ p(\zeta_{[0,t_n]}^*) p(y_{1:r_k^- -1}|\hat{x}_{1:r_k^- -1}^*) }{ p(\zeta_{[0,t_n]}^{(m)}) p(y_{1:r_k^- -1}|\hat{x}_{1:r_k^- -1}^{(m)}) } \nonumber \\
        &   &  \times \frac{ p(\tilde{\zeta}_{k+1}|\zeta_{k}^*) p(y_{r_k^-:r_k^+}|\hat{x}_{r_k^-:r_k^+}^*) }{ p(\tilde{\zeta}_{k+1}|\zeta_{k}^{(m)}) p(y_{r_k^-:r_k^+}|\hat{x}_{r_k^-:r_k^+}^{(m)}) }     \label{eq:MCMC-VRPS_ap}
\end{IEEEeqnarray}

The first fraction is simply a ratio of proposal weights for the current and proposed changepoint histories. The second ratio comprises probabilities which depend solely on the past changepoints, and which are thus the same as values calculated during the filtering stage. These may be stored when first calculated, meaning they can simply be fetched from memory when calculating the acceptance probability.

The third ratio consists of the transition probability between two known changepoints, $\zeta_k$ and $\zeta_{k+1}$, and the likelihood of observations occurring between them. These may be found by calculating the innovation, $v_k$, to get from $\zeta_k$ to $\zeta_{k+1}$. The continuous state trajectory may then be calculated allowing the likelihood terms to be evaluated. The transition density term is given by:

\begin{IEEEeqnarray}{rCl}
 p(\zeta_{k+1}|\zeta_{k}) & = & p(\tau_{k+1}|\tau_{k}) p(v_{k}|v_{k-1})
\end{IEEEeqnarray}

The variable rate particle smoother (VRPS) is summarised below.%in algorithm~\ref{alg:MCMC-VRPS}.

%\begin{algorithm}
 \begin{algorithmic}
  \STATE Run a particle filter to approximate $p(\theta_{[0,t_n]}, x_0|y_{1:n})$ for each $n$.
  \STATE Convert each particle innovation sequence to a changepoint state sequence, to produce approximations of $p(\zeta_{[0,t_n]}|y_{1:n})$.
  \FOR{$i=1 \dots S$}
    \STATE Initialise sampler with $\tilde{\zeta}_{[0,T]}^{(i)} \sim \sum_{j} w_N^{(j)} \delta_{\zeta_{[0,T]}^{(j)}}(\zeta_{[0,T]})$
    \FOR{$n=N \dots 1$}
      \STATE $\zeta_{[0,T]}^{(i)(0)} \gets \tilde{\zeta}_{[0,T]}^{(i)}$.
      \FOR{$m=1 \dots M$}
        \STATE Propose a new past $\zeta_{[0,t_n]}^{(i)*} \sim \sum_j \gamma_n^{(j)} \delta_{(\zeta_{[0,t_n]}^{(j)})}(\zeta_{[0,t_n]})$.
	      \STATE Calculate $\alpha$ using equation~\ref{eq:MCMC-VRPS_ap}
	      \STATE With probability $\alpha$, $\zeta_{[0,t_n]}^{(i)(m)} \gets \zeta_{[0,t_n]}^{(i)*}$. Otherwise $\zeta_{[0,t_n]}^{(i)(m)} \gets \zeta_{[0,t_n]}^{(i)(m-1)}$.
      \ENDFOR
      \STATE $\tilde{\zeta}_{[0,t_n]}^{(i)} \gets \zeta_{[0,t]}^{(i)(M)}$.
    \ENDFOR
  \ENDFOR
 \end{algorithmic}
%\label{alg:MCMC-VRPS}
%\caption{MCMC variable rate particle smoother}
%\end{algorithm}

The number of MH steps, $M$, at each observation time, $n$, allows a trade-off of performance against time. Larger values of $M$ will ensure more unique samples in the smoothing approximation, but will also take longer to execute. In the simulations discussed in this report, $M=1$ was used throughout.






The recursion is initialised by inversion of the observation model. By stacking up the last $L+1$ observations into a single vector, it is possible to write down a joint Gaussian distribution conditional on the $(N-L)$th state. This may be inverted to produce an improper Gaussian density for $x_{N-L}$,
%
\begin{IEEEeqnarray}{rCl}
 \IEEEeqnarraymulticol{3}{l}{p(y_{N-L:N}|x_{N-L}) = \mathcal{N}( \mathbf{y}_{N-L:N} | H_{N-L} x_{N-L}, \Gamma_{N-L} ) } \\
 & \propto & \mathcal{N}(x_{N-L} | (H_{N-L}^T \Gamma_{N-L} H_{N-L})^{-1} H_{N-L}^T \Gamma_{N-L}, (H_{N-L}^T \Gamma_{N-L} H_{N-L})^{-1} )      ,
\end{IEEEeqnarray}

where $H_{N-L}$ and $\Gamma_{N-L}$ may be constructed from the system models and,
%
\begin{IEEEeqnarray}{rCl}
\mathbf{y}_{N-L:N} & = & \begin{bmatrix}y_N \\ y_{N-1} \\ \vdots \\ y_{N-L} \end{bmatrix}     .
\end{IEEEeqnarray}

This should effected for the smallest value of $L$ such that the matrix inversions possible. Further details are provided in appendix~\ref{app:backward_filter}. Alternatively, the recursion could be initialised with an approximation. 